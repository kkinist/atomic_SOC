{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SO-CI information from MOLPRO outputs for atoms\n",
    "#   Read exptl data from Excel file, combine with weights to get E_so\n",
    "#   The experimental Excel file is generated by get_NIST_atomic_data.ipynb\n",
    "# More robust J assignments (attempted)\n",
    "# KKI 8/30/2024\n",
    "# Working for difficult Ta case (9/25/2024)\n",
    "#    (1) get it working for even-electron case (Kr test)\n",
    "#    (2) transparent handling of missing exptl levels in eq. (\n",
    "import re, sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#import random\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import chem_subs as chem\n",
    "#import molpro_subs as mpr\n",
    "import molpro_subs2 as m2\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to format DataFrames\n",
    "fmt = {'Eshift': '{:.1f}', 'degen': '{:d}'}\n",
    "for col in ['J', 'Ecalc', 'E_dif', 'Erel', 'Eshift', 'err', 'Eterm', 'cm-1', 'S',\n",
    "           'wmean', 'wstds', 'uwmean', 'uwstds', 'change', 'rwmse', 'Erel_spread',\n",
    "           'Edav_range_cm']:\n",
    "    fmt[col] =  fmt['Eshift']\n",
    "for col in ['dif', 'Theory', 'ecm', 'SOC', 'RMSE']:\n",
    "    fmt[col] = '{:.2f}'\n",
    "fmt['weight'] = '{:.6f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Molpro SO-CI output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = 'Mo_S1Q18_acvqz-pp.out'  # degenerate levels are problem\n",
    "fname = 'at_2PDPS4PDS_dactzpp.pro'\n",
    "#fname = 'Tc_6SQ26_acvt-pp.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my atom subdirectory names look like \"Ar_I\" (for neutral argon)\n",
    "el = fname.split('_')[0].capitalize()\n",
    "fdir = r'C:\\Users\\irikura\\OneDrive - NIST\\Karl\\atomic_SOC\\calculations\\{:s}_I'.format(el)\n",
    "#fdir = r'C:\\Users\\dagbaglo\\Desktop\\So-ci_energy\\{:s}_I'.format(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsoc = os.sep.join([fdir, fname])\n",
    "print(f'Reading MOLPRO file')\n",
    "print(fsoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the different sections of the output file\n",
    "major_sections, linenos = m2.identify_sections(fsoc)\n",
    "if True:\n",
    "    print('Major sections:')\n",
    "    for k, v in major_sections.items():\n",
    "        print(f'   {k:<11s}   {len(v)} text blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section \"header\"\n",
    "basisset = m2.basisset_name(major_sections['header'][-1])\n",
    "# section \"integrals\"\n",
    "PG = m2.point_group(major_sections['integrals'][-1])\n",
    "print(f'Computational point group = {PG}')\n",
    "if PG != 'Ci':\n",
    "    chem.print_err('', 'Ci point group is required for this analysis')\n",
    "nprim = m2.nbf_primitive(major_sections['integrals'][-1])\n",
    "nbf = m2.nbf(major_sections['integrals'][-1])\n",
    "print(f'{basisset} basis set')\n",
    "print(f'    {nprim} primitives')\n",
    "print(f'    {nbf} contracted basis functions')\n",
    "crd = m2.coordinates(major_sections['integrals'][-1])\n",
    "atom = crd[-1]['el']\n",
    "if atom != el:\n",
    "    chem.print_err('', f'This looks like the wrong atom ({atom}) for the filename ({el})')\n",
    "Qtot = m2.nuclear_charge_total(major_sections['integrals'][-1])\n",
    "print(f'Atom \"{atom}\" with nuclear charge = {Qtot}')\n",
    "Zel = chem.elz(atom, 'Z')\n",
    "if Zel > Qtot:\n",
    "    print(f'    pseudopotential replaces {Zel - Qtot} core electrons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section \"rhf\"\n",
    "try:\n",
    "    occup_hf = m2.hf_occup(major_sections['rhf'][-1])\n",
    "    print('HF occupations: ', occup_hf)\n",
    "    hf_results = m2.scf_result('RHF', major_sections['rhf'][-1])\n",
    "    print('HF energy = {:.6f} for state {:s}'.format(hf_results['E'], hf_results['Label']))\n",
    "    orbtitle, dfHForb = m2.parse_orbitals(major_sections['rhf'][-1])\n",
    "    nel_HF = 0\n",
    "    for otype, occs in occup_hf.items():\n",
    "        if otype == 'alpha/beta':\n",
    "            nel_HF += 2 * sum(occs)\n",
    "        else:\n",
    "            nel_HF += 1 * sum(occs)\n",
    "    print(f'HF has {nel_HF} electrons (charge = {Qtot - nel_HF})')\n",
    "    print(orbtitle)\n",
    "    m2.color_by_orb(dfHForb)\n",
    "except KeyError:\n",
    "    print('No Hartree-Fock step found')\n",
    "    nel_HF = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break section \"multi\" into sub-sections\n",
    "multisec = m2.multi_sections(major_sections['multi'][-1])\n",
    "multisec.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parsing MULTI sub-sections\n",
    "dynfac = m2.get_dynfac(multisec['top'][-1])\n",
    "orbspace = m2.orbital_spaces(multisec['top'][-1])\n",
    "statesym = m2.state_symmetry_groups(multisec['top'][-1])\n",
    "convergence = m2.multi_convergence(multisec['iterations'][-1])\n",
    "weights = m2.multi_weights(multisec['iterations'][-1])\n",
    "dfiter = m2.multi_iterations(multisec['iterations'][-1])\n",
    "dfstates = m2.multi_results(multisec['results'])\n",
    "dfexpec = m2.multi_expec(multisec['trans'][-1])\n",
    "dftrans = m2.multi_transmom(multisec['trans'][-1])\n",
    "orbtitle, dfNO = m2.parse_orbitals(multisec['natorb'][-1])\n",
    "ddfcivec, dEcas = m2.multi_civecs(multisec['civector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nel_CAS = nactel = statesym[0]['nelec']\n",
    "nactorb = sum(orbspace['active'])\n",
    "print(f'CASSCF active space is ({nactel}/{nactorb}) with active orbitals {orbspace[\"active\"]}')\n",
    "if 'closed-shell' in orbspace.keys():\n",
    "    print(f'    closed orbitals are {orbspace[\"closed-shell\"]}')\n",
    "    nel_CAS += 2 * sum(orbspace[\"closed-shell\"])\n",
    "else:\n",
    "    print( '    There are no \"closed\" orbitals')\n",
    "if 'frozen' in orbspace.keys():\n",
    "    print(f'    frozen orbitals are {orbspace[\"frozen\"]}')\n",
    "    nel_CAS += 2 * sum(orbspace[\"frozen\"])\n",
    "else:\n",
    "    print( '    There are no \"frozen\" orbitals')\n",
    "print(f'    charge = {Qtot - nel_CAS}')\n",
    "# Count the states\n",
    "mult_count = {}\n",
    "ncas = 0\n",
    "for st in statesym:\n",
    "    mult = st['spin']\n",
    "    mult_count[mult] = st['nstates'] + mult_count.get(mult, 0)\n",
    "    ncas += st['nstates']\n",
    "print(f'{ncas} CASSCF states:')\n",
    "for mult, n in mult_count.items():\n",
    "    print(f'   {n:3d} {mult}')\n",
    "    \n",
    "# Show the state weights, renormalized for reading convenience\n",
    "print('CASSCF relative state weights (subject to rounding error):')\n",
    "uweights = m2.unnormalize_cas_weights(weights)\n",
    "for k, wts in uweights.items():\n",
    "    print('    ', np.round(wts, 1))\n",
    "    if max(wts) > wts[0] + 0.01:\n",
    "        print('    *** putting a heavy weight on and excited can cause trouble ***')\n",
    "    \n",
    "# Are <L**2> values clean?\n",
    "ilsq = np.rint(dfexpec['L**2'])\n",
    "maxdev = np.abs(ilsq - dfexpec['L**2']).max()\n",
    "if maxdev:\n",
    "    print(f'Largest deviation of <L**2> from integer = {maxdev:.1e}')\n",
    "else:\n",
    "    print('Values of <L**2> are clean')\n",
    "if nel_CAS == nel_HF:\n",
    "    CAS_rel_HF = dfstates.E.min() - hf_results['E']\n",
    "    print(f'For the ground state, [E(CASSCF) - E(HF)] = {CAS_rel_HF:.6f}')\n",
    "    if CAS_rel_HF >= 0:\n",
    "        print('   *** this difference is usually negative')\n",
    "        print('   *** consider using a heavier CASSCF weight on the ground term')\n",
    "elif nel_HF > 0:\n",
    "    print(f'CASSCF and HF have different numbers of electrons ({nel_CAS} and {nel_HF})')\n",
    "print()\n",
    "print(orbtitle)\n",
    "orb_styler = m2.color_by_orb(dfNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # print results from parsing MULTI output\n",
    "    print(f'DYNW = {dynfac}')\n",
    "    print('Spaces: ', orbspace)\n",
    "    print('CASSCF state groups:')\n",
    "    for g in statesym:\n",
    "        print('   ', g)\n",
    "    print(convergence)\n",
    "    print('CASSCF state weights:')\n",
    "    for k, v in weights.items():\n",
    "        print(f'  {k:>2s}: ', v)\n",
    "    display(dfiter)\n",
    "    display(dfstates)\n",
    "    display(dfexpec)\n",
    "    for op, df in dftrans.items():\n",
    "        print(f'Operator {op}')\n",
    "        display(df)\n",
    "    print(orbtitle)\n",
    "    display(dfNO)\n",
    "    for k, df in ddfcivec.items():\n",
    "        print(k, dEcas[k])\n",
    "        display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineg = np.argwhere(dfexpec['L**2'] < 0)\n",
    "if len(ineg) > 0:\n",
    "    print('*** Negative values of <L**2> ***')\n",
    "    display(dfexpec[dfexpec['L**2'] < 0])\n",
    "    ismall = np.argwhere(dfexpec['L**2'].abs() < 1.e-5).flatten().tolist()\n",
    "    #print(ismall)\n",
    "    if len(ismall):\n",
    "        print('Setting small values to zero')\n",
    "        dfexpec.loc[ismall, 'L**2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineg = np.argwhere(dfexpec['LZLZ'] < 0)\n",
    "if len(ineg) > 0:\n",
    "    print('*** Negative values of <LZLZ> ***')\n",
    "    display(dfexpec[dfexpec['LZLZ'] < 0])\n",
    "    ismall = np.argwhere(dfexpec['LZLZ'].abs() < 1.e-5).flatten().tolist()\n",
    "    #print(ismall)\n",
    "    if len(ismall):\n",
    "        print('Setting small values to zero')\n",
    "        dfexpec.loc[ismall, 'LZLZ'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summarize CASSCF results\n",
    "dfcas = dfstates[['Label', 'irrep', 'E']].copy()\n",
    "Svals = []\n",
    "for g in statesym:\n",
    "    for i in range(g['nstates']):\n",
    "        Svals.append(chem.MULTSPIN[g['spin']])\n",
    "dfcas.insert(2, 'S', Svals)\n",
    "dfcas['L**2'] = dfexpec['L**2']\n",
    "dfcas['LZ'] = np.sqrt(dfexpec['LZLZ'])\n",
    "dfcas['L'] = np.sqrt(dfexpec['L**2']).astype(int)\n",
    "tsymb = []\n",
    "for S, L, irr in zip(dfcas.S, dfcas.L, dfcas.irrep):\n",
    "    parity = 3 - 2*irr\n",
    "    trm = chem.term_symbol(L, S, parity, linear=False)\n",
    "    tsymb.append(trm)\n",
    "dfcas['term'] = tsymb\n",
    "print('CASSCF states')\n",
    "dfcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcasterm = m2.collect_atomic_terms(dfcas, 'E')\n",
    "nterm = len(dfcasterm)\n",
    "print(f'There are {ncas} CASSCF states in {nterm} terms')\n",
    "# Add J values\n",
    "Jvals = [chem.possible_J_from_term(trm) for trm in dfcasterm['term']]\n",
    "dfcasterm['J_vals'] = Jvals\n",
    "display(dfcasterm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parse MRCI results and summarize in DataFrame\n",
    "dfmrci = pd.DataFrame()\n",
    "for imrci, sec in enumerate(major_sections['mrci']):\n",
    "    print(f'MRCI calculation #{imrci+1}')\n",
    "    mrcisec = m2.mrci_sections(sec)\n",
    "    mrci_meta = m2.mrci_info(mrcisec['top'][0])\n",
    "    mrci_iter = m2.mrci_iterations(mrcisec['iterations'][0])\n",
    "    mrci_results = m2.mrci_results(mrcisec['results'][0])\n",
    "    nstate = len(mrci_results['state'])\n",
    "    print(f'    {mrci_meta[\"smult\"]}, irrep {mrci_meta[\"irrep\"]}')\n",
    "    print(f'    {nstate} states')\n",
    "    # Report on orbital spaces in the MRCI\n",
    "    print('    orbital spaces, by irrep')\n",
    "    for sp in ['core', 'closed', 'active', 'external']:\n",
    "        print('\\t{:10s} {}'.format(sp, mrci_meta['spaces'].get(sp, [])))\n",
    "    lbll =  []  # list of state labels\n",
    "    c0rot = []  # list of C0 (rotated) values\n",
    "    El =    []  # list of energies\n",
    "    davl =  []  # list of Davidson-corrected energies (rotated ref)\n",
    "    erefl = []  # list of reference energies\n",
    "    spinmult = mrci_meta['smult']\n",
    "    S = chem.MULTSPIN[spinmult]\n",
    "    irrep = mrci_meta['irrep']\n",
    "    for lbl, v in mrci_results['state'].items():\n",
    "        lbll.append(lbl)\n",
    "        try:\n",
    "            c0rot.append(v['C0']['rotated'])\n",
    "            davl.append(v['Energy']['davidson']['rotated'])\n",
    "        except KeyError:\n",
    "            # no \"rotated\" values if there is only one state\n",
    "            c0rot.append(v['C0']['relaxed'])\n",
    "            davl.append(v['Energy']['davidson']['relaxed'])\n",
    "        El.append(v['Energy']['total'])\n",
    "        erefl.append(v['Energy']['ref E'])\n",
    "\n",
    "    # Get CASSCF (fixed) term composition of each MRCI state\n",
    "    fixref = m2.coefficients_of_refs(mrcisec['results'][0])  # coeffs of CASSCF refs\n",
    "    subcas = dfcas[dfcas.S == S]\n",
    "    if nstate == 1:\n",
    "        # 'fixref' is [0] because that text block is not available\n",
    "        # just assign 100% to the only CASSCF reference state\n",
    "        ilead = np.array([0])\n",
    "        fixref = np.array([])\n",
    "        casterm = subcas.iloc[0]['term']\n",
    "        cascomp = [{casterm: 1.}]\n",
    "    else:\n",
    "        ilead = np.zeros(fixref.shape[1]).astype(int)\n",
    "        cascomp = []\n",
    "    for ist in range(fixref.shape[0]):\n",
    "        icas = np.argmax(np.abs(fixref[ist, :]))\n",
    "        ilead[ist] = icas\n",
    "        termd = {}\n",
    "        for icas, c in enumerate(fixref[ist, :]):\n",
    "            casterm = subcas.iloc[icas]['term']\n",
    "            termd[casterm] = termd.get(casterm, 0) + c*c\n",
    "        cascomp.append(termd)\n",
    "    if len(set(ilead)) < len(ilead):\n",
    "        print('    ** Warning: one CASSCF state leads more than one MRCI state')\n",
    "    reflbl = [subcas.iloc[i]['Label'] for i in ilead]\n",
    "    lz = [subcas.iloc[i]['LZ'] for i in ilead]\n",
    "    x = [v for v in mrci_iter['init_ref'].values()][:nstate]\n",
    "    init_refE = [x[i] for i in ilead]\n",
    "    terml = [subcas.iloc[i]['term'] for i in ilead]\n",
    "    data = {'Label': lbll, 'irrep': irrep, 'S': S, 'E': El, 'Edav': davl,\n",
    "            'C0': c0rot, 'Eref': erefl, 'init_ref': init_refE, 'iref_nr': ilead + 1,\n",
    "            'irlbl': reflbl, 'term': terml, 'LZ': lz, 'CASterm': cascomp}\n",
    "    dfci = pd.DataFrame(data)\n",
    "    dfmrci = pd.concat([dfmrci, dfci], ignore_index=True)\n",
    "# add column for difference between reference energy and corresponding CASSCF\n",
    "d_ref = dfmrci.Eref - dfmrci.init_ref\n",
    "dfmrci.insert(8, 'D_ref', d_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for term contamination of MRCI states\n",
    "maxcontam = 0  # largest term contamination across all MRCI states\n",
    "for ici, row in dfmrci.iterrows():\n",
    "    tlead = row.term\n",
    "    twt = row.CASterm\n",
    "    tmax = max(twt, key=twt.get)\n",
    "    if tlead != tmax:\n",
    "        print(f'*** Term confusion for MRCI state! ***')\n",
    "        display(row.to_frame().T)\n",
    "    dcontam = {}\n",
    "    del twt[tlead]  # what is left is contamination\n",
    "    for k in list(twt.keys()):\n",
    "        if twt[k] == 0:\n",
    "            del twt[k]  # omit zero contaminants\n",
    "    maxcontam = max([maxcontam] + list(twt.values()))\n",
    "print(f'Largest MRCI term contamination = {maxcontam:.1e}')\n",
    "# Rename CASterm to CAScontam\n",
    "dfmrci.rename(columns={'CASterm': 'CAScontam'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nmrci = len(dfmrci)\n",
    "#dfmrci\n",
    "dfciterm = m2.collect_atomic_terms(dfmrci, 'Edav')\n",
    "print(f'There are {nmrci} MRCI states in {len(dfciterm)} terms')\n",
    "if nterm != len(dfciterm):\n",
    "    chem.print_err('', 'Different number of terms from CASSCF and from MRCI')\n",
    "# Make prefixes enumerative\n",
    "dfciterm['term'] = chem.enumerative_prefix(dfciterm.term.values, always=False)\n",
    "termsIn = set(dfciterm.term)\n",
    "print('MRCI terms:')\n",
    "styler = dfciterm.style\n",
    "styler = styler.apply(lambda x: [\"background: yellow\" if abs(v) > 5 else \"\" for v in x], \n",
    "              subset=pd.IndexSlice[['Edav_range_cm']])\n",
    "styler.format(fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section \"SOintegrals\"\n",
    "if 'SOintegrals' in major_sections.keys():\n",
    "    SOintgrl = m2.SO_integrals(major_sections['SOintegrals'][0])\n",
    "    #print(SOintgrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break section \"soci\" into sub-sections\n",
    "sosec = m2.soci_sections(major_sections['soci'][0])\n",
    "sosec.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SOCI sub-section 'matel_comput'\n",
    "hlsdiag = m2.soci_replacements(sosec['matel_comput'][0])\n",
    "n_cistates = sum([x['nstate'] for x in hlsdiag.values()])\n",
    "print(f'There are {n_cistates} states in the HLSDIAG list:')\n",
    "# Present a table of old and new diagonal energies, as a check\n",
    "data = {'sym': [], 'S': [], 'old': [], 'HLSDIAG': []}\n",
    "for rec, calc in hlsdiag.items():\n",
    "    for old, new in zip(calc['old'], calc['new']):\n",
    "        data['sym'].append(calc['sym'])\n",
    "        data['S'].append(calc['S'])\n",
    "        data['old'].append(old)\n",
    "        data['HLSDIAG'].append(new)\n",
    "    dfhlsdiag = pd.DataFrame(data=data)\n",
    "    dfhlsdiag['diff'] = dfhlsdiag.HLSDIAG - dfhlsdiag.old\n",
    "styler = dfhlsdiag.style\n",
    "warnThresh = 0.5  # (Hartree) highlight changes in diagonal larger than this\n",
    "styler = styler.apply(lambda x: [\"background: yellow\" if (abs(v) > warnThresh) or (v > 0) else \"\" for v in x], \n",
    "              subset=pd.IndexSlice[['diff']])\n",
    "display(styler.format(fmt))\n",
    "# check for zeros\n",
    "if (np.array(data['HLSDIAG']) == 0).any():\n",
    "    chem.print_err('', 'Zero values in HLSDIAG')\n",
    "mat_elems = m2.soci_matelems(sosec['matel_comput'][0])\n",
    "if mat_elems:\n",
    "    print(mat_elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOCI sub-section 'basis_prop'\n",
    "if 'basis_prop' in sosec.keys():\n",
    "    basprop = m2.soci_basis_prop(sosec['basis_prop'][0], n_cistates)\n",
    "    print(basprop['DMZ'][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOCI sub-section 'so_calc'\n",
    "E0 = m2.soci_E0(sosec['so_calc'][0])\n",
    "print(f'E0 = {E0:.6f} in the SO-CI')\n",
    "somat = m2.soci_matrix(sosec['so_calc'][0])\n",
    "dimen = somat['matrix'].shape[0]\n",
    "print(f'There are {dimen} SO-CI states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero spin-orbit coupling\n",
    "offdiag =somat['matrix'].copy()\n",
    "np.fill_diagonal(offdiag, 0)\n",
    "amax = np.max(np.abs(offdiag))\n",
    "if amax == 0:\n",
    "    print('*** Off-diagonal elements of spin-orbit matrix are all zero ***')\n",
    "    print('There is no spin-orbit coupling')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to basis-state info: MRCI and term parentage, LZ etc.\n",
    "for i, bas in enumerate(somat['basis']):\n",
    "    S = bas['S']\n",
    "    lbl = bas['State']\n",
    "    subdf = dfmrci[(dfmrci.Label == lbl) & (dfmrci.S == S)]\n",
    "    #display(subdf)\n",
    "    ici = subdf.index[0]\n",
    "    bas['ici'] = ici\n",
    "    for iterm, trow in dfciterm.iterrows():\n",
    "        if ici in trow.idx:\n",
    "            bas['iterm'] = iterm\n",
    "            break\n",
    "    # Add LZ\n",
    "    bas['LZ'] = np.round(subdf.loc[ici, 'LZ'], 5)\n",
    "    bas['JZ'] = set([abs(bas['Sz'] - bas['LZ']), abs(bas['Sz'] + bas['LZ'])])\n",
    "    # find the minimum Jz\n",
    "    minJ = min(bas['JZ'])\n",
    "    # round minJ up\n",
    "    minJ = np.rint(minJ - bas['Sz']) + bas['Sz']\n",
    "    tlbl = dfciterm.loc[bas['iterm'], 'term']  # term label\n",
    "    jposs = np.array(chem.possible_J_from_term(tlbl))\n",
    "    bas['Jterm'] = set(jposs)\n",
    "    # J cannot be less than Jz\n",
    "    jposs = jposs[jposs >= minJ]\n",
    "    bas['Jposs'] = set(jposs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SOCI sub-section 'so_levels'\n",
    "so_energies = m2.soci_energies(sosec['so_levels'][0])\n",
    "df_soE = pd.DataFrame(so_energies)\n",
    "print(f'There are {len(df_soE)} spin-orbit levels')\n",
    "df_soE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCraw = min(so_energies['Eshift'])\n",
    "print(f'From lowest level and lowest uncoupled term energy, raw theoretical SOCraw = {SOCraw:.2f} cm-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO-CI sub-section 'so_vectors'\n",
    "# In case of symmetry blocking, the last one should be the summary\n",
    "so_vecs = m2.soci_vectors(sosec['so_vectors'][-1])\n",
    "so_vecs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check eigenvectors for normality\n",
    "#    eigenvectors are columns of so_vecs['matrix']\n",
    "tol = 1.e-7\n",
    "mat = so_vecs['matrix']\n",
    "for i in range(dimen):\n",
    "    prod = np.dot(np.conjugate(mat[:, i]), mat[:, i])\n",
    "    if np.abs(1 - prod) > tol:\n",
    "        print(i, i, ':  ', prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check eigenvectors for orthogonality\n",
    "#    eigenvectors are columns of so_vecs['matrix']\n",
    "mat = so_vecs['matrix']\n",
    "for i in range(dimen):\n",
    "    for j in range(i):\n",
    "        prod = np.dot(np.conjugate(mat[:, i]), mat[:, j])\n",
    "        if np.abs(prod) > tol:\n",
    "            print(i, j, ':  ', np.abs(prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SO-CI sub-section 'so_compos'\n",
    "so_compos = m2.soci_composition(sosec['so_compos'][0])\n",
    "so_compos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all listings of basis states are consistent\n",
    "for a, b, c in zip(somat['basis'], so_vecs['basis'], so_compos['basis']):\n",
    "    for k in a.keys():\n",
    "        if (k in b.keys()) and (k in c.keys()):\n",
    "            if (a[k] != b[k]) or (a[k] != c[k]):\n",
    "                print(a)\n",
    "                print(b)\n",
    "                print(c)\n",
    "                print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that composition is consistent with eigenvectors\n",
    "magnit = np.conjugate(so_vecs['matrix']) * so_vecs['matrix']\n",
    "# get differences in percent (printed by Molpro to 0.01% precision)\n",
    "difmat = (magnit * 100) - so_compos['matrix']\n",
    "dmax = np.abs(difmat).max()\n",
    "print(f'Largest inconsistency between composition and eigenvectors = {dmax:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert basis-state compositions (percent) to term compositions\n",
    "use_printed = False  # use composition % as printed by Molpro (less precise)\n",
    "if use_printed:\n",
    "    # compositions are printed to 0.001% precision\n",
    "    print('Using rounded compositions as printed by Molpro')\n",
    "    magpct = so_compos['matrix']\n",
    "else:\n",
    "    # eigenvectors are orthonormal and printed to 1e-8 precision\n",
    "    print('Using compositions derived from eigenvectors')\n",
    "    magpct = np.real(magnit * 100)\n",
    "term_compos = np.zeros((nterm, dimen))\n",
    "for ibas in range(dimen):\n",
    "    iterm = somat['basis'][ibas]['iterm']\n",
    "    term_compos[iterm,:] += magpct[ibas,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Display composition of one SO-CI state\n",
    "    iso = 26\n",
    "    wts = magpct[:, iso]  # basis-state weights\n",
    "    dflevcomp = pd.DataFrame({'wt_bas': np.round(wts, 6)})\n",
    "    dflevcomp['bas_Jposs'] = [x['Jposs'] for x in somat['basis']]\n",
    "    dflevcomp['S'] = [x['S'] for x in somat['basis']]\n",
    "    dflevcomp['Sz'] = [x['Sz'] for x in somat['basis']]\n",
    "    dflevcomp['ici'] = [x['ici'] for x in somat['basis']]\n",
    "    dflevcomp['iterm'] = [x['iterm'] for x in somat['basis']]\n",
    "    dflevcomp['term'] = [dfmrci.loc[x['ici'], 'term'] for x in somat['basis']]\n",
    "    dflevcomp['term_Jposs'] = [chem.possible_J_from_term(trm) for trm in dflevcomp['term']]\n",
    "    display(dflevcomp.sort_values('wt_bas', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add J values to dfciterm\n",
    "jpossl = []\n",
    "for term in dfciterm.term:\n",
    "    jposs = chem.possible_J_from_term(term)\n",
    "    jpossl.append(jposs)\n",
    "dfciterm['J'] = jpossl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_index(x):\n",
    "    # Given a term symbol, return its index in dfciterm\n",
    "    # Given an index, return the term symbol from dfciterm\n",
    "    global dfciterm\n",
    "    try:\n",
    "        trm = dfciterm.at[x, 'term']\n",
    "        return trm\n",
    "    except:\n",
    "        try:\n",
    "            i = dfciterm.index[dfciterm.term == x].tolist()[0]\n",
    "            return i\n",
    "        except IndexError:\n",
    "            # invalid term\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target J counts corresponding to the CASSCF terms\n",
    "allJ = []\n",
    "for jl in dfcasterm['J_vals']:\n",
    "    allJ.extend(jl)\n",
    "J_all = dict(Counter(allJ))\n",
    "print('Required level counts     :', J_all)\n",
    "nlevels = len(allJ)\n",
    "print(f'    There are {nlevels} J-levels')\n",
    "Jxg = {k: int(v * (2*k+1)) for k, v in J_all.items()}\n",
    "J_left = Jxg.copy()  # copy to be decremented\n",
    "print('Required sublevel counts:', Jxg)\n",
    "#df_soE['J'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign values of <em>J</em>  to levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_possible_J(df_soE, basis_descr, magpct, style='term', thrpct=10.):\n",
    "    '''\n",
    "    Add set of possible J values to each level/row of df_soE\n",
    "        also add their count\n",
    "    Return nothing\n",
    "    Args: df_soE       DataFrame of SO-CI levels\n",
    "          basis_descr  list of dict; info about each basis state\n",
    "          magpct       square array, pct weights of basis states, indices [ibas, iso]\n",
    "          style        either 'term' or 'basis state'; which to use in determining J poss\n",
    "          thrpct       pct threshold for including terms or basis states\n",
    "    '''\n",
    "    if style == 'term':\n",
    "        choice = 'Jterm'  # key in basis-state description\n",
    "    elif style == 'basis state':\n",
    "        choice = 'Jposs'\n",
    "    else:\n",
    "        chem.print_err('', '*** Argument \"style\" must be either \"term\" or \"basis state\"')\n",
    "    Jpossl = []  # list of sets\n",
    "    for iso, row in df_soE.iterrows():\n",
    "        bascomp = magpct[:, iso]  # composition vector for this level\n",
    "        idx = np.argwhere(bascomp > thrpct).flatten()\n",
    "        if len(idx) == 0:\n",
    "            # in rare case that no basis state contributes 'thrpct' %\n",
    "            idx = [np.argmax(bascomp)]\n",
    "        for k, i in enumerate(idx):\n",
    "            if k == 0:\n",
    "                Jposs = basis_descr[i][choice]\n",
    "            else:\n",
    "                # take intersection among sets of significant terms or basis states\n",
    "                Jposs = Jposs.intersection(basis_descr[i][choice])\n",
    "        Jpossl.append(Jposs)\n",
    "    df_soE['J_poss'] = Jpossl\n",
    "    df_soE['nposs'] = [len(s) for s in Jpossl]\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_possible_J(df_soE, somat['basis'], magpct, 'term', thrpct=10.)\n",
    "# Add term composition vector (complete and also rounded)\n",
    "df_soE['TC_approx'] = list(np.round(term_compos, 1).T)\n",
    "df_soE['term_comp'] = list(term_compos.T)\n",
    "# make column for final J values\n",
    "df_soE['J'] = None  # yet unassigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for 0-possibility problems\n",
    "subdf = df_soE[df_soE.nposs < 1]\n",
    "n0 = len(subdf)  # number of levels with no possible values of J\n",
    "# Check for insufficient possibilities\n",
    "inadequate = []  # list of J with insufficient possible values\n",
    "for J in J_left.keys():\n",
    "    dfJ = m2.Jposs_subdf(df_soE, J)\n",
    "    nposs = len(dfJ)\n",
    "    if nposs < J_left[J]:\n",
    "        inadequate.append(J)\n",
    "        display(dfJ)\n",
    "if n0 or inadequate:\n",
    "    if n0:\n",
    "        print('*** Some levels have all possibilities eliminated ***')\n",
    "    if inadequate:\n",
    "        print(f'*** Some J values have insufficient possible levels: {inadequate}')\n",
    "    print(f'\\nThis means that the term weights are defective at the {thrpct}% level.')\n",
    "    print('If you don\\'t care, you can try increasing that threshold (\"thrpct\").')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make backup copies in case J assignment fails at first\n",
    "df_soE_bak = df_soE.copy()\n",
    "J_left_bak = J_left.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To assign J, first try Kmeans clustering based upon energy and term composition\n",
    "#     as done in atomic_soc8.ipynb\n",
    "\n",
    "# Assemble vectors needed by Kmeans()\n",
    "Escale = 10.  # this many cm-1 is on par with 1% composition\n",
    "Xwt = np.transpose(term_compos)\n",
    "xe = df_soE.Erel.values / Escale\n",
    "xe = xe.reshape((-1,1))\n",
    "X = np.hstack((Xwt, xe))\n",
    "nlevel = sum(J_all.values())\n",
    "print(f'Assigning J using {nlevel} clusters/levels...')\n",
    "Kmean = KMeans(n_clusters=nlevel, n_init=10)\n",
    "try:\n",
    "    Kmean.fit(X)\n",
    "    J_fail = False\n",
    "except:\n",
    "    print('*** Clustering failed ***')\n",
    "    J_fail = True\n",
    "impossl = []\n",
    "if not J_fail:\n",
    "    xmeans = [x[-1] for x in Kmean.cluster_centers_]  # cluster mean (Erel/Escale) values\n",
    "    Emeans = np.array(xmeans) * Escale\n",
    "    df_soE['ilev'] = Kmean.labels_\n",
    "    Jfound = []\n",
    "    J_fail = False\n",
    "    for ilev, grp in df_soE.groupby('ilev'):\n",
    "        g = len(grp)\n",
    "        J = np.round((g-1)/2, 1)\n",
    "        df_soE.loc[df_soE.ilev == ilev, 'J'] = J\n",
    "        Jfound.append(J)\n",
    "    # Error-checking of assignments\n",
    "    if Counter(Jfound) != J_all:\n",
    "        print('*** J values found are not J values expected! ***')\n",
    "        print('Expected:', sorted(J_all.items()))\n",
    "        J_clust = Counter(Jfound)\n",
    "        print('Found   :', sorted(J_clust.items()))\n",
    "        J_fail = True\n",
    "    for irow, row in df_soE.iterrows():\n",
    "        if row.J not in row.J_poss:\n",
    "            print(f'Level {irow} has J = {row.J} but that is not among ' +\n",
    "                  f'possibilities {sorted(row.J_poss)}')\n",
    "            J_fail = True\n",
    "            impossl.append(irow)\n",
    "    if len(impossl):\n",
    "        print('\\n*** These \"impossible\" assignments may mean that term compositions are unreliable ***')\n",
    "        display(df_soE.loc[impossl, ['Erel', 'J_poss', 'TC_approx', 'J']].style.format(fmt))\n",
    "if not J_fail:\n",
    "    print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if J_fail:\n",
    "    print('*** Kmeans failed to assign reasonable values of J ***')\n",
    "    print('Examine the calculated levels for possible assignments of J')\n",
    "    display(df_soE_bak[['Erel', 'J_poss', 'nposs', 'TC_approx']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_best_group_for_J(df_soE, J_left, J):\n",
    "    # For the given value of J, find the tightest groups of levels\n",
    "    #    that are reasonably isolated\n",
    "    # Return the groups as list of:\n",
    "    #    indices, marginal DataFrame, E-spread, TC-spread, E-margin, TC-margin\n",
    "    # KKI 11/1/2024\n",
    "    degen = int(2*J + 1)\n",
    "    ngroup = J_left[J] // degen\n",
    "    df_unassigned = df_soE[df_soE['J'].isnull()]\n",
    "    dfJ = m2.Jposs_subdf(df_unassigned, J)\n",
    "    #display(dfJ[['Erel', 'J_poss', 'TC_approx']])\n",
    "    ilo = []\n",
    "    sprE = []\n",
    "    sprTC = []\n",
    "    margE = []\n",
    "    margTC = []\n",
    "    subdf_list = []\n",
    "    for i in range(len(dfJ) - degen + 1):\n",
    "        subdf = dfJ.iloc[i : i+degen]\n",
    "        Espr, TCspr, maxTC = m2.spreads_ETC(subdf)\n",
    "        if Espr is None:\n",
    "            # set to zero\n",
    "            Espr = maxTC = 0.\n",
    "            TCspr = np.zeros(len(df_soE.loc[0, 'term_comp']))\n",
    "        ilo.append(i)\n",
    "        sprE.append(Espr)\n",
    "        sprTC.append(maxTC)\n",
    "        Esep = TCsep = np.inf  # separation from adjacent levels\n",
    "        llim = i\n",
    "        ulim = i + degen\n",
    "        if i > 0:\n",
    "            llim -= 1\n",
    "            spr, cspr, maxcspr = m2.spreads_ETC(dfJ.iloc[i-1 : i+degen])\n",
    "            Esep = min(Esep, spr - Espr)\n",
    "            TCsep = min(TCsep, maxcspr - maxTC)\n",
    "        if (i + degen) < len(dfJ):\n",
    "            ulim += 1\n",
    "            spr, cspr, maxcspr = m2.spreads_ETC(dfJ.iloc[i : i+degen+1])\n",
    "            Esep = min(Esep, spr - Espr)\n",
    "            TCsep = min(TCsep, maxcspr - maxTC)\n",
    "        margE.append(Esep)\n",
    "        margTC.append(maxTC)\n",
    "        subdf_list.append(dfJ.iloc[llim:ulim][['Erel', 'J_poss', 'nposs', 'TC_approx', 'J']])\n",
    "    retval = []\n",
    "    for i in np.argsort(sprE):\n",
    "        # loop over groupings from tightest to loosest\n",
    "        if margE[i] < (2 * sprE[i]):\n",
    "            # degenerate with adjacent level\n",
    "            continue\n",
    "        # add to the list\n",
    "        idx = dfJ.index.values[i : i+degen]\n",
    "        retval.append([idx, subdf_list[i], sprE[i], sprTC[i], margE[i], margTC[i]])\n",
    "        if len(retval) == ngroup:\n",
    "            break\n",
    "    return retval\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if J_fail:\n",
    "    # discard any (failed) assignments\n",
    "    df_soE = df_soE_bak\n",
    "    J_left = J_left_bak\n",
    "    \n",
    "    # try the simplest tricks\n",
    "    thr_degen = 5 # cm-1\n",
    "    thr_tcomp = 3 # percent\n",
    "    df_soE['ilev'] = -1\n",
    "    \n",
    "    def highlight_rows(row):\n",
    "        if row.name in idx:  # Highlight rows with index 0 and 2\n",
    "            return ['background-color: lightgreen'] * len(row)\n",
    "        else:\n",
    "            return [''] * len(row)\n",
    "    \n",
    "    nass_singl = m2.singletons_J(df_soE, J_left, thr_degen, thr_tcomp, verbose=True)\n",
    "    nass_goldi = m2.poss_count_just_right(df_soE, J_left, thr_degen, thr_tcomp, verbose=True)\n",
    "    print('\\n--- Look for best-separated groups of degeneracy (2J + 1) ---')\n",
    "    for J in sorted(J_left.keys(), reverse=True):\n",
    "        if J_left[J] < 1:\n",
    "            # no more assignments to make\n",
    "            print(f'J = {J} is fully assigned')\n",
    "            continue\n",
    "        degen = int(2 * J + 1)\n",
    "        print(f'--- look for {J_left[J] // degen} groups with J = {J}')\n",
    "        candi = J_best_group_for_J(df_soE, J_left, J)\n",
    "        for idx, dfx, sprE, sprTC, margE, margTC in candi:\n",
    "            styler = dfx.style.apply(highlight_rows, axis=1)\n",
    "            display(styler)\n",
    "            ok = input(f'Do you approve assigning this group to J={chem.halves(J)}? ')\n",
    "            if 'n' not in ok.lower():\n",
    "                m2.record_J_assignment(df_soE, J_left, idx, J)\n",
    "                print('OK')\n",
    "                # try the easy things again, now that changes were made\n",
    "                nass_singl = m2.singletons_J(df_soE, J_left, thr_degen, thr_tcomp, verbose=True)\n",
    "                nass_goldi = m2.poss_count_just_right(df_soE, J_left, thr_degen, thr_tcomp,\n",
    "                                                      verbose=True)\n",
    "            else:\n",
    "                print('discarding possible assignment')\n",
    "    J_fail = False\n",
    "    for J, unk in J_left.items():\n",
    "        if unk > 0:\n",
    "            J_fail = True\n",
    "            break\n",
    "    if J_fail:\n",
    "        print(f'\\n*** There are still {len(df_soE[\"J\"].isnull())} unassigned levels ***')\n",
    "    else:\n",
    "        print('\\n=== All levels have been assigned ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if J_fail:\n",
    "    print('**** J assignments failed, cannot proceed ****')\n",
    "    for J, nleft in J_left.items():\n",
    "        if nleft:\n",
    "            print(f'J = {J} needs {nleft} levels assigned')\n",
    "    \n",
    "    def highlight_unassigned(row):\n",
    "        if row.J is None:\n",
    "            return ['background-color: yellow'] * len(row)\n",
    "        else:\n",
    "            return [''] * len(row)\n",
    "    \n",
    "    # Add energy increment column, display, and quit\n",
    "    erel = df_soE.Erel.values\n",
    "    df_soE['dE'] = [0] + list(erel[1:] - erel[:-1])\n",
    "    styler = df_soE[['Erel', 'dE', 'ilev', 'J', 'J_poss', 'TC_approx']].style\n",
    "    styler = styler.apply(highlight_unassigned, axis=1)\n",
    "    #styler = styler.apply(lambda x: [\"background: yellow\" if v is None else \"\" for v in x], \n",
    "    #          subset=pd.IndexSlice[['J']])\n",
    "    display(styler.format({'Erel': '{:.1f}', 'dE': '{:.1f}'}))\n",
    "\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After successful J assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add leading terms to df_soE (all levels from the SO-CI)\n",
    "Tlead = []\n",
    "ileadl = []\n",
    "for tc in df_soE.term_comp:\n",
    "    ilead = np.argmax(tc)\n",
    "    Tlead.append(dfciterm.loc[ilead, 'term'])\n",
    "    ileadl.append(ilead)\n",
    "df_soE['Lead'] = Tlead\n",
    "df_soE['ilead'] = ileadl\n",
    "# Create new DataFrame of aggregated levels\n",
    "avg = {}\n",
    "cols = list(df_soE.columns) + ['idx']\n",
    "for col in cols:\n",
    "    avg[col] = []\n",
    "for ilev, grp in df_soE.groupby('ilev'):\n",
    "    #print('ilev =', ilev)\n",
    "    #display(grp)\n",
    "    for col in cols:\n",
    "        try:\n",
    "            avg[col].append(grp[col].mean())\n",
    "        except TypeError:\n",
    "            # string such as symbol of leading term\n",
    "            avg[col].append(grp[col].values[0])\n",
    "        except KeyError:\n",
    "            # 'idxl' column not yet created\n",
    "            avg['idx'].append(list(grp.index.values))\n",
    "dflev = pd.DataFrame({k: avg[k] for k in cols})\n",
    "# adjust values of TC_approx\n",
    "for i, row in dflev.iterrows():\n",
    "    #dflev.at[i, 'TC_approx'] = np.round(row.term_comp, 1) # fails when length=1\n",
    "    dflev.at[i, 'TC_approx'] = [np.round(x, 1) for x in row.term_comp]\n",
    "# sort by energy\n",
    "dflev.sort_values('E', inplace=True, ignore_index=True)\n",
    "# Create labels from Term + J\n",
    "Jlbl = []\n",
    "for trm, J in zip(dflev.Lead, dflev.J):\n",
    "    Jlbl.append(f'{trm}_{chem.halves(J)}')\n",
    "dflev['Jlbl'] = Jlbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information about scatter among supposedly degenerate sublevels\n",
    "espread = []\n",
    "tcspread = []\n",
    "for ilev, row in dflev.iterrows():\n",
    "    idx = row.idx\n",
    "    esp = np.ptp(df_soE.loc[idx, 'Erel'])\n",
    "    espread.append(esp)\n",
    "    tc = np.vstack(df_soE.loc[idx, 'term_comp'])\n",
    "    tcptp = np.ptp(tc, axis=0)\n",
    "    tcspread.append(np.round(tcptp, 1))\n",
    "dflev['Erel_spread'] = espread\n",
    "dflev['TC_spread'] = tcspread\n",
    "print('Check the table below for questionable grouping of levels')\n",
    "print('\"Erel_spread\" shows how much the energies differ within a level (cm-1)')\n",
    "print('\"TC_spread\" shows how much the term compositions differ within a level (%)')\n",
    "print('\"idx\" shows which magnetic sublevels in \"df_soE\" compose each level')\n",
    "dflev[['J', 'Erel', 'Erel_spread', 'TC_spread', 'idx']].style.format(fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert term compositions 'TC_approx' from numpy arrays to dicts, sorted from largest\n",
    "#    to smallest weight, and with negligible weights omitted\n",
    "twl = []\n",
    "for TC in dflev.TC_approx:\n",
    "    if TC is None:\n",
    "        twl.append(None)\n",
    "    else:\n",
    "        twd = {dfciterm.at[i,'term']: wt for i, wt in enumerate(TC) if wt >= 0.1}\n",
    "        tcsort = chem.sort_dict_by_value(twd, reverse=True)\n",
    "        twl.append(tcsort)\n",
    "dflev['termwt'] = twl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Level assignments from the calculation:')\n",
    "showcols = ['Lead', 'J', 'Jlbl', 'Erel', 'Eshift', 'termwt']\n",
    "display(dflev[showcols].style.format(fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there duplicated leading terms?\n",
    "dups = False\n",
    "for j, grp in dflev.groupby('J'):\n",
    "    leads = list(grp.Lead)\n",
    "    if len(leads) > len(set(leads)):\n",
    "        print(f'*** Duplicate leading term for J = {j} ***')\n",
    "        dups = True\n",
    "        for lead in set(leads):\n",
    "            leads.remove(lead)\n",
    "        dfdup = grp[grp.Lead.isin(leads)].copy()\n",
    "        #display(dfdup[showcols].style.format(fmt))\n",
    "        styler = grp[showcols].style\n",
    "        styler = styler.apply(lambda x: [\"background: yellow\" if v in leads else \"\" for v in x], \n",
    "              subset=pd.IndexSlice[['Lead']])\n",
    "        display(styler.format(fmt))\n",
    "        unlead = set() # terms that are not leading\n",
    "        for twd in dfdup.termwt:\n",
    "            for trm, wt in twd.items():\n",
    "                if trm not in list(grp.Lead):\n",
    "                    unlead.add(trm)\n",
    "        print('Terms not leading: ', unlead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change assignments of any duplicates\n",
    "if dups:\n",
    "    print('Correct the duplicate term assignments, if you wish')\n",
    "    for trm in unlead:\n",
    "        ifix = input(f'Level to label with {trm} (blank to ignore)? ')\n",
    "        if len(ifix):\n",
    "            ifix = int(ifix)\n",
    "            dflev.loc[ifix, 'Lead'] = trm\n",
    "            iterm = dfciterm.index[dfciterm.term == trm]\n",
    "            dflev.loc[ifix, 'ilead'] = iterm\n",
    "    # rebuild 'Jlbl' values\n",
    "    jlbl = [f'{t}_{chem.halves(j)}' for t, j in zip(dflev.Lead, dflev.J)]\n",
    "    dflev['Jlbl'] = chem.enumerative_prefix(jlbl)\n",
    "    display(dflev[['Lead', 'J', 'Jlbl', 'Erel', 'Eshift']].style.format(fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for problems in assignments\n",
    "nAssign = len(set(dflev.Lead))\n",
    "nTerm = len(dfciterm)\n",
    "dropT = False\n",
    "if nAssign != nTerm:\n",
    "    print(f'*** I started with {nTerm} terms but have {nAssign} leading terms ***')\n",
    "    print('Starting: ', sorted(termsIn))\n",
    "    termsOut = set(dflev.Lead)\n",
    "    print('Leading : ', sorted(termsOut))\n",
    "    if nAssign > nTerm:\n",
    "        addT = termsOut - termsIn\n",
    "        print('Added terms: ', addT)\n",
    "    else:\n",
    "        dropT = termsIn - termsOut\n",
    "        print('Dropped terms: ', dropT)\n",
    "        # Add weights from dropped terms and display\n",
    "        for term in dropT:\n",
    "            wtcol = []\n",
    "            for comp in dflev.termwt:\n",
    "                pct = comp.get(term, 0)\n",
    "                wtcol.append(pct)\n",
    "            dflev[term] = wtcol\n",
    "            fmt[term] = '{:.1f}'\n",
    "        print('Weights (%) of dropped terms in levels:')\n",
    "        display(dflev[['Lead', 'J', 'Jlbl', 'Erel', 'Eshift'] + list(dropT)].style.format(fmt))\n",
    "nlvl = (2 * dflev.J + 1).sum()  # number of sublevels\n",
    "if nlvl != dimen:\n",
    "    print(f'*** I started with {nSO} (sub)levels but now have {nlvl} ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually assign any dropped terms\n",
    "if dropT:\n",
    "    for drt in dropT:\n",
    "        ia = input(f'Which level do you want to assign to term {drt} (blank to ignore)? ')\n",
    "        if len(ia) > 0:\n",
    "            ia = int(ia)\n",
    "            dflev.loc[ia, 'Lead'] = drt\n",
    "            iterm = dfciterm.index[dfciterm.term == drt]\n",
    "            dflev.loc[ia, 'ilead'] = iterm\n",
    "    # rebuild 'Jlbl' values\n",
    "    jlbl = [f'{t}_{chem.halves(j)}' for t, j in zip(dflev.Lead, dflev.J)]\n",
    "    dflev['Jlbl'] = chem.enumerative_prefix(jlbl)\n",
    "    display(dflev[['Lead', 'J', 'Jlbl', 'Erel', 'Eshift'] + list(dropT)].style.format(fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inversion parity of the calculated levels\n",
    "irreps_ci = set(dfciterm.irrep)\n",
    "if (PG == 'Ci') and (len(irreps_ci) == 1):\n",
    "    if 1 in irreps_ci:\n",
    "        parity = 'even'\n",
    "    else:\n",
    "        parity = 'odd'\n",
    "else:\n",
    "    # ask user for parity of interest\n",
    "    parity = input('Please choose \"even\" or \"odd\" parity: ')\n",
    "print(f'Experimental states will be restricted to parity = {parity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read experimental energy levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge = Qtot - mrci_meta['nelec']  # number of electrons in the last MRCI\n",
    "labels_ordinated = False  # flag to prevent multiple (1)(1)(1) etc. \n",
    "if charge >= 0:\n",
    "    atstr = atom + '_' + 'I' * (charge + 1)\n",
    "else:\n",
    "    # anion\n",
    "    atstr = atom + '_neg'\n",
    "fxl = f'{atstr}_exptl_levels.xlsx'\n",
    "xlpath = os.sep.join([fdir, fxl])\n",
    "dfexpt = pd.read_excel(xlpath)\n",
    "if type(dfexpt.J.values[0]) is str:\n",
    "    fmt['J'] = '{:s}'\n",
    "print(f'Experimental energy levels read from {fxl}')\n",
    "# If there is a column \"comment\", replace NaN with ''\n",
    "if 'comment' in dfexpt.columns:\n",
    "    dfexpt['comment'] = dfexpt['comment'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of decimal places in the level energies\n",
    "Ecol = 'Level (cm-1)'  # the exptl energy column\n",
    "ndecim = 0\n",
    "for e in dfexpt[Ecol]:\n",
    "    words = str(e).split('.')\n",
    "    # count numeric digits\n",
    "    n = sum(c.isdigit() for c in words[-1])\n",
    "    ndecim = max(n, ndecim)\n",
    "print(f'Experimental energies are provided to {ndecim} decimal digits')\n",
    "# display formatting\n",
    "fmt[Ecol] = '{:.' + str(ndecim) + 'f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Delete any ionization limit\n",
    "ilim = dfexpt[dfexpt.Term == 'Limit'].index.min()\n",
    "# delete the \"Limit\" row and everything past it\n",
    "n1 = len(dfexpt)\n",
    "dfexpt = dfexpt.truncate(after=ilim-1)\n",
    "n2 = len(dfexpt)\n",
    "if n2 < n1:\n",
    "    print(f'Discarding {n1-n2} ionized or metastable states')\n",
    "oddstr = r'\\*$|°' # characters to identify terms of odd parity\n",
    "# Sometimes parity is shown in configuration alone?\n",
    "#dfeven = dfexpt[~(dfexpt.Term.str.contains(oddstr) | dfexpt.Configuration.str.contains(oddstr))].copy()\n",
    "#dfodd = dfexpt[dfexpt.Term.str.contains(oddstr) | dfexpt.Configuration.str.contains(oddstr)].copy()\n",
    "dfeven = dfexpt[~(dfexpt.Term.str.contains(oddstr))].copy()\n",
    "dfodd = dfexpt[dfexpt.Term.str.contains(oddstr)].copy()\n",
    "print(f'{len(dfexpt)} experimental levels ({len(dfeven)} even and {len(dfodd)} odd)')\n",
    "# Select by parity\n",
    "if parity == 'even':\n",
    "    # discard odd levels ('Term' field ends with '*')\n",
    "    dfexpt = dfeven.copy()\n",
    "elif parity == 'odd':\n",
    "    dfexpt = dfodd.copy()\n",
    "else:\n",
    "    chem.print_err('', f'Parity of \"{parity}\" is not recognized')\n",
    "n3 = len(dfexpt)\n",
    "print(f'{n3} levels accepted for parity = {parity}')\n",
    "# Reject bad values of J\n",
    "for i in dfexpt.index:\n",
    "    try:\n",
    "        chem.halves_to_float(dfexpt.loc[i, 'J'])\n",
    "    except ValueError:\n",
    "        dfexpt.at[i, 'J'] = np.nan\n",
    "nbad = dfexpt.J.isna().sum()\n",
    "if nbad:\n",
    "    print(f'** Rejecting {nbad} levels with malformed J values')\n",
    "    dfexpt = dfexpt.dropna()\n",
    "    n4 = len(dfexpt)\n",
    "    print(f'{n4} level retained')\n",
    "# Assign unique term symbols\n",
    "if not labels_ordinated:\n",
    "    dfexpt = chem.unique_labels_exptl_terms(dfexpt, verbose=True, always=True)\n",
    "    labels_ordinated = True\n",
    "# Add column for degeneracy\n",
    "dfexpt['degen'] = (2 * dfexpt.J.apply(chem.halves_to_float)).astype(int) + 1\n",
    "# Remove any troublesom non-ascii whitespace characters\n",
    "dfexpt.Term = [' '.join(t.split()) for t in dfexpt.Term]\n",
    "dfexpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match experimental and theoretical levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_term_symbol(symb_expt, symb_calc):\n",
    "    # Return True if they are the same, else False\n",
    "    # Tolerate extra prefix '(1)' or 'a' in symb_expt\n",
    "    a = str(symb_expt)\n",
    "    b = str(symb_calc)\n",
    "    retval = (a == b)  # exact match\n",
    "    tx = ''\n",
    "    if ('(1)' in a[:-len(b)]) or ('a' in a):\n",
    "        tx = a[-len(b):]   # match last characters\n",
    "        retval |= (b == tx)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termwt_to_dict(termwt):\n",
    "    # Given a list/Series of term weight arrays,\n",
    "    # Return a corresponding list of dict where key = term label\n",
    "    twl = []\n",
    "    for TC in termwt:\n",
    "        if TC is None:\n",
    "            twl.append(None)\n",
    "        else:\n",
    "            twd = {dfciterm.at[i,'term']: wt for i, wt in enumerate(TC) if wt >= 0.1}\n",
    "            # sort from largest to smallest weights\n",
    "            twd = chem.sort_dict_by_value(twd, reverse=True)\n",
    "            twl.append(twd)\n",
    "    return twl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def match_theory_to_expt(dfth, dfx, bigerr=3000):\n",
    "    '''\n",
    "    Match experimental levels to theoretical\n",
    "    Return a DataFrame containing both theory and expt, and\n",
    "      the index of the highest level matched\n",
    "    'bigerr' is in cm-1 and triggers extra scrutiny\n",
    "    '''\n",
    "    print('Matching experimental levels with theoretical levels')\n",
    "    Jlist = sorted(set(dfth.J))\n",
    "    dfcomp = dfexpt.copy()\n",
    "    dfcomp['Tcalc'] = ''  # term assignment in computation\n",
    "    dfcomp['leadwt'] = ''\n",
    "    dfcomp['Ecalc'] = np.nan\n",
    "    dfcomp['termwt'] = None\n",
    "    dfcomp['Composition'] = None\n",
    "    imax = 0  # index of highest exptl level matched\n",
    "    for J in Jlist:\n",
    "        print(f'J = {J}')\n",
    "        # get the indices of the exptl levels that best match theoretical\n",
    "        dfJth = dfth[dfth.J == J]\n",
    "        #display(dfJth[['Lead', 'J', 'Erel', 'TC_approx']])\n",
    "        dfJx = dfx[dfx.J == J]\n",
    "        if len(dfJx) < 1:\n",
    "            # try str representation\n",
    "            hJstr = chem.halves(J)  # as str fraction\n",
    "            dfJx = dfx[dfx.J == hJstr]\n",
    "        #display(dfJx)\n",
    "        idx = match_th_expt_1J_V2(dfJth, dfJx, bigerr=bigerr)\n",
    "        #print(f'>>>J = {J}, num theor = {len(dfJth)}, idx = {idx}')\n",
    "        for i, ix in enumerate(idx):\n",
    "            rowth = dfJth.iloc[i]\n",
    "            dfcomp.at[ix, 'Tcalc'] = rowth.Lead\n",
    "            dfcomp.at[ix, 'leadwt'] = rowth.TC_approx[term_index(rowth.Lead)]\n",
    "            dfcomp.at[ix, 'Ecalc'] = rowth.Erel\n",
    "            dfcomp.at[ix, 'termwt'] = rowth.TC_approx\n",
    "            dfcomp.at[ix, 'Composition'] = [x for x in rowth.term_comp] # fix when length=1\n",
    "            imax = max(imax, ix)\n",
    "    # Convert approx. 'termwt' from numpy arrays to dicts, sorted from largest to \n",
    "    #    smallest weight, and with negligible weights omitted\n",
    "    dfcomp['termwt'] = termwt_to_dict(dfcomp.termwt)\n",
    "    return dfcomp, imax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_th_expt_1J_V2(dfJth, dfJx, bigerr=3000):\n",
    "    '''\n",
    "    Given DataFrame's of theoretical and experimental levels for the same J,\n",
    "    Return a list of indices into dfJx that match those in dfJth\n",
    "        based upon energy, but with preference for same leading term\n",
    "    'bigerr' is in cm-1 and triggers extra scrutiny\n",
    "    '''\n",
    "    idx = []  # index of exptl level that matches each theor level\n",
    "    for i, row in dfJth.iterrows():\n",
    "        Eth = row.Erel\n",
    "        thTerm = row.Lead\n",
    "\n",
    "        def same_Lead(xTerm):\n",
    "            # Does the exptl \"uTerm\" match the theoretical \"Lead\"?\n",
    "            return match_term_symbol(xTerm, thTerm)\n",
    "    \n",
    "        # Is there an exptl level with the same leading term?\n",
    "        termatch = dfJx.uTerm.apply(same_Lead)\n",
    "        subx = dfJx.loc[termatch]\n",
    "        if len(subx) == 1:\n",
    "            # The nicest situation, but check the energy\n",
    "            err = abs(Eth - subx[Ecol].values[0])\n",
    "            if err < bigerr:\n",
    "                # tolerable\n",
    "                print(f'    exptl term \"{subx.Term.iloc[0]}\" matches leading \"{thTerm}\"')\n",
    "                j = subx.index.values[0]\n",
    "                idx.append(j)\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "                #print(f'    exptl term \"{subx.Term.iloc[0]}\" rejected as match for' +\n",
    "                #      f' leading \"{thTerm}\" because energy error = {err:.0f} cm-1')\n",
    "        # There are multiple or no matching terms\n",
    "        #   rely upon energy ordering (among matching terms, if any)\n",
    "        if len(subx) > 1:\n",
    "            # Exptl data assign the same leading term to multiple levels of this J (unusual)\n",
    "            #print(f'    leading \"{thTerm}\" matches multiple exptl terms \"{subx.Term.values}\"')\n",
    "            pass\n",
    "        else:\n",
    "            # No matching term symbols\n",
    "            #print(f'    leading \"{thTerm}\" matches no exptl term labels')\n",
    "            subx = dfJx  # consider all levels because none match the term symbol\n",
    "        j = None\n",
    "        for j, rowx in subx.iterrows():\n",
    "            # expect energy ordering to be similar\n",
    "            #    there is no way to detect inversions\n",
    "            if j in idx:\n",
    "                # this exptl level already matched\n",
    "                continue\n",
    "            # we get here if this level has not yet been matched; take the first one\n",
    "            print(f'    leading \"{thTerm}\" matched with exptl \"{rowx.Term}\"')\n",
    "            # check the energy\n",
    "            err = Eth - rowx[Ecol]\n",
    "            if abs(err) > bigerr:\n",
    "                print(f'\\t*** but large energy error of {err:.0f} cm-1 ***')\n",
    "                if err < 0:\n",
    "                    print('\\t*** maybe an experimental level is missing')\n",
    "            break\n",
    "        if (j is not None) and (j not in idx):\n",
    "            idx.append(j)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Match theoretical and experimental levels\n",
    "# imax is the index of the highest-energy level matched\n",
    "dfdiff, imax = match_theory_to_expt(dflev, dfexpt)\n",
    "dfdiff['err'] = dfdiff.Ecalc - dfdiff[Ecol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = dfdiff.loc[imax, 'Tcalc']\n",
    "J = dfdiff.loc[imax, 'J']\n",
    "levmax = f'{t}_{J}'\n",
    "emax = dfdiff.loc[imax, Ecol]\n",
    "showcols = ['Configuration', 'uTerm', 'Tcalc', 'J', Ecol, 'Ecalc', 'err', 'termwt']\n",
    "print(f'Highest level matched is {levmax} at {emax} cm-1 (exptl energy)')\n",
    "# Notify about any exptl levels that the calculation skipped over\n",
    "dfskipped = dfdiff[dfdiff.Ecalc.isna()].loc[:imax]\n",
    "if len(dfskipped):\n",
    "    print('\\n*** The following experimental levels are skipped over in the calculation ***')\n",
    "    print(  '***     Consider doing another calculation with these levels included     ***')\n",
    "    display(dfskipped[showcols])\n",
    "    #display(dfdiff.loc[:imax][showcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert str values of J to float\n",
    "dfdiff['J'] = dfdiff.J.apply(chem.halves_to_float)\n",
    "fmt['J'] = '{:.1f}'\n",
    "warnThresh = 1000  # highlight errors larger than this (cm-1)\n",
    "# drop rows with NaN (no matching level in the calculation)\n",
    "dfdiff_all = dfdiff.copy()\n",
    "dfdiff.dropna(axis=0, inplace=True)\n",
    "# sort by increasing calculated energy, and re-index\n",
    "dfdiff.sort_values('Ecalc', inplace=True, ignore_index=True)\n",
    "# Update the exptl term enumerative prefixes to reflect this subset of terms\n",
    "dfdiff['uTerm'] = chem.update_enumerative_prefix(dfdiff.uTerm)\n",
    "selcols = ['Configuration', 'uTerm', 'J', Ecol, 'Tcalc', 'Ecalc', 'err']\n",
    "# Print a warning if experimental levels are missing\n",
    "nth = len(dflev); ndiff = len(dfdiff)\n",
    "expt_missing = nth - ndiff\n",
    "if expt_missing > 0:\n",
    "    print(f'\\n**** There are {nth} theoretical levels but only {ndiff} ' +\n",
    "          'matching experimental levels ****\\n')\n",
    "    setdiff = set(dfdiff.Ecalc)\n",
    "    setth = set(dflev.Erel)\n",
    "    missing = setth - setdiff\n",
    "    dfunmatched = dflev[dflev.Erel.isin(missing)].copy()\n",
    "    print('Unmatched theoretical levels:')\n",
    "    display(dfunmatched[['Erel', 'J', 'Lead', 'Jlbl', 'termwt']].style.format(fmt))\n",
    "else:\n",
    "    # use as flag\n",
    "    expt_missing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if expt_missing:\n",
    "    print('*** Installing theoretical levels where no exptl levels could be matched ***')\n",
    "    dfu = dfunmatched.rename(columns={'Lead': 'Tcalc', 'Erel': 'Ecalc', \n",
    "                'term_comp': 'Composition'})\n",
    "    dfu['degen'] = (2 * dfu.J + 1).astype(int)\n",
    "    # add column for weight of leading term\n",
    "    lwt = [twt[lt] for lt, twt in zip(dfunmatched.Lead, dfunmatched.termwt)]\n",
    "    dfu['leadwt'] = lwt\n",
    "    # install theoretical energies as \"experimental\"\n",
    "    dfu[Ecol] = dfu.Ecalc\n",
    "    dfu['err'] = 0\n",
    "    dfu['Configuration'] = ''\n",
    "    dfu['Term'] = ''\n",
    "    dfu['uTerm'] = ''\n",
    "    # drop unwanted columns\n",
    "    dfu = dfu.drop(columns=['Eshift', 'J_poss', 'nposs', 'TC_approx', 'ilev', 'ilead',\n",
    "                     'idx', 'Jlbl', 'Erel_spread', 'TC_spread', 'E'])\n",
    "    dfdiff = pd.concat([dfdiff, dfu])\n",
    "    dfdiff = dfdiff.sort_values(Ecol).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'comment' in dfdiff.columns:\n",
    "    selcols.append('comment')\n",
    "print(f'Please inspect the following pairing of theory (\"Ecalc\") with expt (\"{Ecol}\")')\n",
    "print(f'Errors > {warnThresh} cm-1 are highlighted in yellow')\n",
    "show_skipped = False  # display the skipped levels (if any) in the table below\n",
    "if len(dfskipped) and show_skipped:\n",
    "    # also show the skipped/unmatched exptl levels\n",
    "    styler = dfdiff_all[showcols].style\n",
    "else:\n",
    "    styler = dfdiff[showcols].style\n",
    "styler = styler.apply(lambda x: [\"background: yellow\" if abs(v) > warnThresh else \"\" for v in x], \n",
    "              subset=pd.IndexSlice[['err']])\n",
    "if (len(dfskipped) == 0) or (not show_skipped):\n",
    "    print('Disagreements in term assignments are highlighted in red')\n",
    "    styler = styler.apply(lambda x: (x != dfdiff['uTerm']).map({True: \"background-color: red; \\\n",
    "                  color: white\", False: \"\"}), subset=['Tcalc'])\n",
    "display(styler.format(fmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute spin-orbit corrections, <em>E</em><sub>so</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No theoretical calculations are needed to use eq. (1)\n",
    "# I.e., accept experimental term assignments and assume that each level\n",
    "#    derives from a single term (100% term weight)\n",
    "xterms = []  # list of exptl term labels\n",
    "thterms = [] # list of theoretical term labels\n",
    "eterms = []  # list of term energies\n",
    "for term in dfdiff.uTerm:\n",
    "    if term not in xterms:\n",
    "        xterms.append(term)\n",
    "for term in dfdiff.Tcalc:\n",
    "    if term not in thterms:\n",
    "        thterms.append(term)\n",
    "for Term in xterms:\n",
    "    subdf = dfdiff[dfdiff.uTerm == Term]\n",
    "    emean = np.dot(subdf.degen, subdf[Ecol]) / subdf.degen.sum()\n",
    "    eterms.append(emean)\n",
    "dfeq1 = pd.DataFrame({'Term': xterms, 'Eterm': eterms}).sort_values('Eterm').reset_index(drop=True)\n",
    "print('In the naive model of eq. (1), experimental term assignments are accepted')\n",
    "print('    and each level is assumed to derive from a single term (100% term weight).')\n",
    "print('Term energies (cm-1) using eq. (1) [no theoretical input]:')\n",
    "display(dfeq1.style.format(fmt))\n",
    "SOC1 = -1 * np.round(dfeq1.at[0, 'Eterm'], 3)\n",
    "lowterm = dfeq1.at[0, 'Term']\n",
    "print(f'The exptl term of lowest energy is *** {lowterm} *** with SOC1 = {SOC1} cm-1')\n",
    "levterm = dfdiff.uTerm.values[0]\n",
    "\n",
    "target = levterm\n",
    "\n",
    "if lowterm != levterm:\n",
    "    # The lowest term is not the leading term of the lowest level\n",
    "    SOC1alt = SOC1\n",
    "    SOC1 = -1 * np.round(dfeq1[dfeq1.Term == levterm]['Eterm'].values[0], 3)\n",
    "    print(f'The lowest level belongs to \\t{levterm} \\twith SOC1 = {SOC1} cm-1')\n",
    "\n",
    "# Check for rare situation\n",
    "th_term = dfdiff[dfdiff.uTerm == target].Tcalc.values[0]\n",
    "if th_term != target:\n",
    "    # hopefully just the enumerative prefix\n",
    "    print(f'    *** changing target term from {target} to {th_term}')\n",
    "    old_target = target\n",
    "    target = th_term\n",
    "print()\n",
    "print(f'Term {target} is selected for calculating the spin-orbit correction')\n",
    "print('    to change this, assign the variable \"target\" to another term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_energy_from_levels(df, term, returnDF=False):\n",
    "    # Given a DataFrame with columns ['J', 'Composition', Ecol],\n",
    "    #   where (variable) Ecol is the header for the column of exptl level energies,\n",
    "    # Return the term's average energy as derived from the levels [eq. (2) in pub.]\n",
    "    # If 'returnDF', also return a DataFrame for the selected term\n",
    "    # 'term' is from theory\n",
    "    iterm = term_index(term)\n",
    "    if iterm is None:\n",
    "        # invalid term\n",
    "        return None, None\n",
    "    termwt = []  # weight of term \"term\" in each level\n",
    "    for tc in df.Composition.values:\n",
    "        termwt.append(tc[iterm])\n",
    "    termwt = np.array(termwt)\n",
    "    dweight = df.degen.values * termwt  # weights should include degeneracies\n",
    "    # take product of experimental energies and theoretical term weights\n",
    "    Eterm = np.dot(df[Ecol], dweight) / dweight.sum()\n",
    "    if not returnDF:\n",
    "        return Eterm\n",
    "    # Construct DF showing distribution of term among levels\n",
    "    cols = ['Configuration', 'uTerm', 'Tcalc', 'J', 'degen', Ecol, 'Ecalc', 'err']\n",
    "    df_distrib = df[cols].copy()\n",
    "    df_distrib.insert(0, 'weight', termwt / 100)  # fraction instead of percent\n",
    "    return Eterm, df_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Term of interest is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nDistribution of target term {target} among levels:')\n",
    "Eterm, df_distrib = term_energy_from_levels(dfdiff, target, returnDF=True)\n",
    "# Combine degeneracy with weight\n",
    "df_distrib.insert(0, target, df_distrib.weight * df_distrib.degen)\n",
    "subdf = df_distrib[df_distrib[target] > 1.e-6].copy()\n",
    "# suppress redundant columns\n",
    "subdf = subdf.drop(columns=['weight', 'degen'])\n",
    "styler = subdf.sort_values(target, ascending=False).style\n",
    "styler = styler.apply(lambda x: [\"background: yellow\" if abs(v) > warnThresh else \"\" for v in x], \n",
    "              subset=pd.IndexSlice[['err']])\n",
    "display(styler.format(fmt))\n",
    "ibad = subdf[subdf.err.abs() > 3000]\n",
    "print(f'Sum of displayed weights = {subdf[target].sum():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of very large errors, allow replacement of exptl energy with theoretical\n",
    "ibad = subdf[subdf.err.abs() > 3000]\n",
    "if len(ibad):\n",
    "    print('Some errors in level energies are very large:')\n",
    "    display(ibad.style.format(fmt))\n",
    "    idxl = []\n",
    "    while True:\n",
    "        idx = input('Level to replace exptl energy with theoretical (blank to end): ')\n",
    "        if idx:\n",
    "            idxl.append(int(idx))\n",
    "        else:\n",
    "            break\n",
    "    for i in idxl:\n",
    "        dfdiff.at[i, Ecol] = dfdiff.at[i, 'Ecalc']\n",
    "        dfdiff.at[i, 'err'] = 0\n",
    "    if len(idxl):\n",
    "        print('Energies replaced')\n",
    "        ibad = ibad.index.values\n",
    "        display(dfdiff.loc[ibad].style.format(fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of large errors of opposite sign, consider different match with expt\n",
    "ibad = subdf[subdf.err.abs() > 3000]\n",
    "swapped = False\n",
    "if len(ibad):\n",
    "    # Is max ~ -min?\n",
    "    if abs(ibad.err.max() + ibad.err.min()) < 1000:\n",
    "        imax = ibad.err.idxmax()\n",
    "        imin = ibad.err.idxmin()\n",
    "        if ibad.at[imin, 'J'] == ibad.at[imax, 'J']:\n",
    "            # can only switch equal J\n",
    "            q = input(f'Swap the matches for rows {imin} and {imax}? ')\n",
    "            if 'n' == q.lower()[0]:\n",
    "                print('Keeping old match')\n",
    "            else:\n",
    "                print('Swapping matches')\n",
    "            for col in ['Tcalc', 'Ecalc', 'leadwt', 'termwt', 'Composition']:\n",
    "                x = dfdiff.at[imin, col]\n",
    "                dfdiff.at[imin, col] = dfdiff.at[imax, col]\n",
    "                dfdiff.at[imax, col] = x\n",
    "            for i in [imin, imax]:\n",
    "                dfdiff.at[i, 'err'] = dfdiff.at[i, 'Ecalc'] - dfdiff.at[i, Ecol]\n",
    "            swapped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use experimental level energies via eq. (2) (from the publication)\n",
    "Eterm, df_distrib = term_energy_from_levels(dfdiff, target, returnDF=True)\n",
    "if swapped:\n",
    "    # display the modified matching scheme \n",
    "    subdf = df_distrib[df_distrib.weight > 1.e-6]\n",
    "    styler = subdf.sort_values('weight', ascending=False).style\n",
    "    styler = styler.apply(lambda x: [\"background: yellow\" if abs(v) > warnThresh else \"\" for v in x], \n",
    "                  subset=pd.IndexSlice[['err']])\n",
    "    print('Matching scheme after swapping:')\n",
    "    display(styler.format(fmt))\n",
    "SOC2 = -Eterm\n",
    "print('Applying eq. (2) (experimental energies and theoretical term weights).')\n",
    "print(f'For term {target}, SOC2 = {SOC2:.2f} cm-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Molpro source file: {fname}\\n')\n",
    "print(f'Alternative values for E_so[{target}] of atom {atom}:')\n",
    "print('-' * 25)\n",
    "print('{:12s} {:.2f} cm-1\\t (term {:s})'.format('eq (1)', SOC1, old_target))\n",
    "print('{:12s} {:.2f} cm-1'.format('raw theory', SOCraw))\n",
    "print('{:12s} {:.2f} cm-1'.format('eq (2)', SOC2))\n",
    "print('-' * 25)\n",
    "print(f'\\nDifference [eq. (2)] - [eq. (1)]    = {SOC2-SOC1:.1f} cm-1')\n",
    "print(f'Difference [eq. (2)] - [raw theory] = {SOC2-SOCraw:.1f} cm-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term energy errors as inferred from all levels\n",
    "termlist = []\n",
    "wmean = []\n",
    "wstds = []\n",
    "# also consider unsigned (absolute value) errors\n",
    "uwmean = []\n",
    "uwstds = []\n",
    "# also consider RMSE\n",
    "trmse = []\n",
    "for term in set(dfdiff.Tcalc):\n",
    "    eterm, df_distro = term_energy_from_levels(dfdiff, term, returnDF=True)\n",
    "    if eterm is None:\n",
    "        print(f'No theoretical term matches exptl {term}')\n",
    "        continue\n",
    "    termlist.append(term)\n",
    "    wts = df_distro.weight.values * df_distro.degen\n",
    "    m, s = chem.weighted_mean(df_distro.err, wts)\n",
    "    wmean.append(m)\n",
    "    wstds.append(s)\n",
    "    uerr = np.abs(df_distro.err.values)\n",
    "    um, us = chem.weighted_mean(uerr, wts)\n",
    "    uwmean.append(um)\n",
    "    uwstds.append(us)\n",
    "    umsq, ussq = chem.weighted_mean(uerr ** 2, wts)\n",
    "    trmse.append(np.sqrt(umsq))\n",
    "dftermerr = pd.DataFrame({'Term': termlist, 'wmean': wmean, 'wstds': wstds,\n",
    "                         'uwmean': uwmean, 'uwstds': uwstds, 'rwmse': trmse})\n",
    "print('Errors in term energies (cm-1) as inferred from the full distribution')\n",
    "print('    of each term over all levels')\n",
    "# default order same as experimental terms\n",
    "dftermerr.Term = pd.Categorical(dftermerr.Term, thterms)\n",
    "dftermerr = dftermerr.sort_values('Term')\n",
    "styler = dftermerr.style\n",
    "styler = styler.apply(lambda x: [\"background: yellow\" if abs(v) > warnThresh else \"\" for v in x], \n",
    "              subset=pd.IndexSlice[['wmean']])\n",
    "styler.format(fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional distribution of some other term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_term = '7S' #'4P°'\n",
    "Eterm, df_distrib = term_energy_from_levels(dfdiff, other_term, returnDF=True)\n",
    "if Eterm is None:\n",
    "    print(f'Cannot evaluate errors for levels within term \"{other_term}\"')\n",
    "else:\n",
    "    print(f'Distribution of term {other_term} among levels:')\n",
    "    subdf = df_distrib[df_distrib.weight >= 1.e-6]\n",
    "    display(subdf.sort_values('weight', ascending=False).style.format(fmt))\n",
    "    wtot = df_distrib.weight.sum()\n",
    "    dwtot = np.dot(df_distrib.weight, df_distrib.degen)\n",
    "    print('Total weight = {:.3f} ({:.3f} including degeneracies)'.format(wtot, dwtot))\n",
    "    print(f'Eq. (2) term energy = {Eterm:.1f} cm-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
