{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SO-CI information from MOLPRO outputs for atoms\n",
    "#   Read exptl data from Excel file, combine with weights to get E_so\n",
    "#   The experimental Excel file is generated by get_NIST_atomic_data.ipynb\n",
    "# More robust J assignments (attempted)\n",
    "# KKI 8/30/2024\n",
    "# Working for difficult Ta case (9/25/2024)\n",
    "# TO DO:\n",
    "#    (1) get it working for even-electron case (Kr test)\n",
    "#    (2) transparent handling of missing exptl levels in eq. (\n",
    "import re, sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.cluster import KMeans\n",
    "\n",
    "import chem_subs as chem\n",
    "import molpro_subs as mpr\n",
    "import molpro_subs2 as m2\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Molpro SO-CI output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = 'kr_1SDPS_3SDP_dac5z_87_w99.pro'\n",
    "fname = 'Ta_Q10D28S5_cvtz-pp.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my atom subdirectory names look like \"Ar_I\" (for neutral argon)\n",
    "el = fname.split('_')[0].capitalize()\n",
    "fdir = r'C:\\Users\\irikura\\OneDrive - NIST\\Karl\\atomic_SOC\\calculations\\{:s}_I'.format(el)\n",
    "#fdir = r'C:\\Users\\dagbaglo\\Desktop\\So-ci_energy\\{:s}_I'.format(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsoc = os.sep.join([fdir, fname])\n",
    "print(f'Reading MOLPRO file')\n",
    "print(fsoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the different sections of the output file\n",
    "major_sections, linenos = m2.identify_sections(fsoc)\n",
    "if False:\n",
    "    print('Major sections:')\n",
    "    for k, v in major_sections.items():\n",
    "        print(f'   {k:<11s}   {len(v)} text blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section \"header\"\n",
    "basisset = m2.basisset_name(major_sections['header'][-1])\n",
    "# section \"integrals\"\n",
    "PG = m2.point_group(major_sections['integrals'][-1])\n",
    "print(f'Computational point group = {PG}')\n",
    "if PG != 'Ci':\n",
    "    chem.print_err('', 'Ci point group is required for this analysis')\n",
    "nprim = m2.nbf_primitive(major_sections['integrals'][-1])\n",
    "nbf = m2.nbf(major_sections['integrals'][-1])\n",
    "print(f'{basisset} basis set')\n",
    "print(f'    {nprim} primitives')\n",
    "print(f'    {nbf} contracted basis functions')\n",
    "crd = m2.coordinates(major_sections['integrals'][-1])\n",
    "atom = crd[-1]['el']\n",
    "if atom != el:\n",
    "    chem.print_err('', f'This looks like the wrong atom ({atom}) for the filename ({el})')\n",
    "Qtot = m2.nuclear_charge_total(major_sections['integrals'][-1])\n",
    "print(f'Atom \"{atom}\" with nuclear charge = {Qtot}')\n",
    "Zel = chem.elz(atom, 'Z')\n",
    "if Zel > Qtot:\n",
    "    print(f'    pseudopotential replaces {Zel - Qtot} core electrons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section \"rhf\"\n",
    "occup_hf = m2.hf_occup(major_sections['rhf'][-1])\n",
    "print('HF occupations: ', occup_hf)\n",
    "hf_results = m2.scf_result('RHF', major_sections['rhf'][-1])\n",
    "print('HF energy = {:.6f} for state {:s}'.format(hf_results['E'], hf_results['Label']))\n",
    "orbtitle, dfHForb = m2.parse_orbitals(major_sections['rhf'][-1])\n",
    "nel_HF = sum(sum(v) for v in occup_hf.values())\n",
    "print(f'HF has {nel_HF} electrons (charge = {Qtot - nel_HF})')\n",
    "print(orbtitle)\n",
    "m2.color_by_orb(dfHForb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break section \"multi\" into sub-sections\n",
    "multisec = m2.multi_sections(major_sections['multi'][-1])\n",
    "#multisec.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parsing MULTI sub-sections\n",
    "dynfac = m2.get_dynfac(multisec['top'][-1])\n",
    "orbspace = m2.orbital_spaces(multisec['top'][-1])\n",
    "statesym = m2.state_symmetry_groups(multisec['top'][-1])\n",
    "convergence = m2.multi_convergence(multisec['iterations'][-1])\n",
    "weights = m2.multi_weights(multisec['iterations'][-1])\n",
    "dfiter = m2.multi_iterations(multisec['iterations'][-1])\n",
    "dfstates = m2.multi_results(multisec['results'])\n",
    "dfexpec = m2.multi_expec(multisec['trans'][-1])\n",
    "dftrans = m2.multi_transmom(multisec['trans'][-1])\n",
    "orbtitle, dfNO = m2.parse_orbitals(multisec['natorb'][-1])\n",
    "ddfcivec, dEcas = m2.multi_civecs(multisec['civector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nactel = statesym[0]['nelec']\n",
    "nactorb = sum(orbspace['active'])\n",
    "print(f'CASSCF active space is ({nactel}/{nactorb}) with active orbitals {orbspace[\"active\"]}')\n",
    "if 'closed-shell' in orbspace.keys():\n",
    "    print(f'    closed orbitals are {orbspace[\"closed-shell\"]}')\n",
    "else:\n",
    "    print( '    There are no \"closed\" orbitals')\n",
    "if 'frozen' in orbspace.keys():\n",
    "    print(f'    frozen orbitals are {orbspace[\"frozen\"]}')\n",
    "else:\n",
    "    print( '    There are no \"frozen\" orbitals')\n",
    "# Count the states\n",
    "mult_count = {}\n",
    "ncas = 0\n",
    "for st in statesym:\n",
    "    mult = st['spin']\n",
    "    mult_count[mult] = st['nstates'] + mult_count.get(mult, 0)\n",
    "    ncas += st['nstates']\n",
    "print(f'{ncas} CASSCF states:')\n",
    "for mult, n in mult_count.items():\n",
    "    print(f'   {n:3d} {mult}')\n",
    "    \n",
    "# Show the state weights, renormalized for reading convenience\n",
    "print('CASSCF relative state weights (subject to rounding error):')\n",
    "uweights = m2.unnormalize_cas_weights(weights)\n",
    "for k, wts in uweights.items():\n",
    "    print('    ', np.round(wts, 1))\n",
    "    \n",
    "# Are <L**2> values clean?\n",
    "ilsq = np.rint(dfexpec['L**2'])\n",
    "maxdev = np.abs(ilsq - dfexpec['L**2']).max()\n",
    "if maxdev:\n",
    "    print(f'Largest deviation of <L**2> from integer = {maxdev:.1e}')\n",
    "else:\n",
    "    print('Values of <L**2> are clean')\n",
    "CAS_rel_HF = dfstates.E.min() - hf_results['E']\n",
    "print(f'For the ground state, [E(CASSCF) - E(HF)] = {CAS_rel_HF:.6f}')\n",
    "if CAS_rel_HF >= 0:\n",
    "    print('   *** this difference should normally be negative')\n",
    "print()\n",
    "print(orbtitle)\n",
    "orb_styler = m2.color_by_orb(dfNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # print results from parsing MULTI output\n",
    "    print(f'DYNW = {dynfac}')\n",
    "    print('Spaces: ', orbspace)\n",
    "    print('CASSCF state groups:')\n",
    "    for g in statesym:\n",
    "        print('   ', g)\n",
    "    print(convergence)\n",
    "    print('CASSCF state weights:')\n",
    "    for k, v in weights.items():\n",
    "        print(f'  {k:>2s}: ', v)\n",
    "    display(dfiter)\n",
    "    display(dfstates)\n",
    "    display(dfexpec)\n",
    "    for op, df in dftrans.items():\n",
    "        print(f'Operator {op}')\n",
    "        display(df)\n",
    "    print(orbtitle)\n",
    "    display(dfNO)\n",
    "    for k, df in ddfcivec.items():\n",
    "        print(k, dEcas[k])\n",
    "        display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summarize CASSCF results\n",
    "dfcas = dfstates[['Label', 'irrep', 'E']].copy()\n",
    "Svals = []\n",
    "for g in statesym:\n",
    "    for i in range(g['nstates']):\n",
    "        Svals.append(chem.MULTSPIN[g['spin']])\n",
    "dfcas.insert(2, 'S', Svals)\n",
    "dfcas['L**2'] = dfexpec['L**2']\n",
    "dfcas['L'] = np.sqrt(dfexpec['L**2']).astype(int)\n",
    "tsymb = []\n",
    "for S, L, irr in zip(dfcas.S, dfcas.L, dfcas.irrep):\n",
    "    parity = 3 - 2*irr\n",
    "    trm = chem.term_symbol(L, S, parity, linear=False)\n",
    "    tsymb.append(trm)\n",
    "dfcas['term'] = tsymb\n",
    "print('CASSCF states')\n",
    "dfcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcasterm = m2.collect_atomic_terms(dfcas)\n",
    "nterm = len(dfcasterm)\n",
    "print(f'There are {ncas} CASSCF states in {nterm} terms')\n",
    "# Add J values\n",
    "Jvals = [chem.possible_J_from_term(trm) for trm in dfcasterm['term']]\n",
    "dfcasterm['J_vals'] = Jvals\n",
    "display(dfcasterm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse MRCI results and summarize in DataFrame\n",
    "dfmrci = pd.DataFrame()\n",
    "for imrci, sec in enumerate(major_sections['mrci']):\n",
    "    print(f'MRCI calculation #{imrci+1}')\n",
    "    mrcisec = m2.mrci_sections(sec)\n",
    "    mrci_meta = m2.mrci_info(mrcisec['top'][0])\n",
    "    mrci_iter = m2.mrci_iterations(mrcisec['iterations'][0])\n",
    "    mrci_results = m2.mrci_results(mrcisec['results'][0])\n",
    "    nstate = len(mrci_results['state'])\n",
    "    print(f'    {mrci_meta[\"smult\"]}, irrep {mrci_meta[\"irrep\"]}')\n",
    "    print(f'    {nstate} states')\n",
    "    # Report on orbital spaces in the MRCI\n",
    "    print('    orbital spaces, by irrep')\n",
    "    for sp in ['core', 'closed', 'active', 'external']:\n",
    "        print('\\t{:10s} {}'.format(sp, mrci_meta['spaces'].get(sp, [])))\n",
    "    lbll =  []  # list of state labels\n",
    "    c0rot = []  # list of C0 (rotated) values\n",
    "    El =    []  # list of energies\n",
    "    davl =  []  # list of Davidson-corrected energies (rotated ref)\n",
    "    erefl = []  # list of reference energies\n",
    "    spinmult = mrci_meta['smult']\n",
    "    S = chem.MULTSPIN[spinmult]\n",
    "    irrep = mrci_meta['irrep']\n",
    "    for lbl, v in mrci_results['state'].items():\n",
    "        lbll.append(lbl)\n",
    "        try:\n",
    "            c0rot.append(v['C0']['rotated'])\n",
    "            davl.append(v['Energy']['davidson']['rotated'])\n",
    "        except KeyError:\n",
    "            # no \"rotated\" values if there is only one state\n",
    "            c0rot.append(v['C0']['relaxed'])\n",
    "            davl.append(v['Energy']['davidson']['relaxed'])\n",
    "        El.append(v['Energy']['total'])\n",
    "        erefl.append(v['Energy']['ref E'])\n",
    "    init_ref_no = [k for k in mrci_iter['init_ref'].keys()][:nstate]\n",
    "    reflbl_tentat = [f'{i}.{irrep}' for i in init_ref_no]\n",
    "    init_refE = [v for v in mrci_iter['init_ref'].values()][:nstate]\n",
    "    dfci = pd.DataFrame({'Label': lbll, 'irrep': irrep, 'S': S, 'E': El,\n",
    "                        'Edav': davl, 'C0': c0rot, 'Eref': erefl, \n",
    "                        'init_ref': init_refE, 'iref_nr': init_ref_no,\n",
    "                        'irlbl': reflbl_tentat})\n",
    "    # find matching CASSCF reference\n",
    "    etol = 1.e-6  # tolerance for matching reference energies\n",
    "    caslbll = []\n",
    "    castrml = []\n",
    "    subcas = dfcas[dfcas.S == S]\n",
    "    for ici, cirow in dfci.iterrows():\n",
    "        irlbl = reflbl_tentat[ici]\n",
    "        subrow = subcas[subcas.Label.str.contains(irlbl)]\n",
    "        if abs(subrow.iloc[0]['E'] - cirow['init_ref']) < etol:\n",
    "            # this is a match\n",
    "            caslbll.append(subrow.iloc[0]['Label'])\n",
    "            castrml.append(subrow.iloc[0]['term'])\n",
    "        else:\n",
    "            # something wrong\n",
    "            caslbll.append('?')\n",
    "            castrml.append('?')\n",
    "    dfci['ref_lbl'] = caslbll\n",
    "    dfci['term'] = castrml\n",
    "    if '?' in caslbll:\n",
    "        print('    *** failure matching MRCI states to CASSCF states')\n",
    "        display(dfci)\n",
    "    dfmrci = pd.concat([dfmrci, dfci], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nmrci = len(dfmrci)\n",
    "#dfmrci\n",
    "dfciterm = m2.collect_atomic_terms(dfmrci, 'Edav')\n",
    "termsIn = set(dfciterm.term)\n",
    "print(f'There are {nmrci} MRCI states in {len(dfciterm)} terms')\n",
    "if nterm != len(dfciterm):\n",
    "    chem.print_err('', 'Different number of terms from CASSCF and from MRCI')\n",
    "# Make prefixes enumerative\n",
    "dfciterm['term'] = chem.enumerative_prefix(dfciterm.term.values)\n",
    "print('MRCI terms:')\n",
    "dfciterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section \"SOintegrals\"\n",
    "if 'SOintegrals' in major_sections.keys():\n",
    "    SOintgrl = m2.SO_integrals(major_sections['SOintegrals'][0])\n",
    "    #print(SOintgrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break section \"soci\" into sub-sections\n",
    "sosec = m2.soci_sections(major_sections['soci'][0])\n",
    "#sosec.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SOCI sub-section 'matel_comput'\n",
    "hlsdiag = m2.soci_replacements(sosec['matel_comput'][0])\n",
    "n_cistates = sum([x['nstate'] for x in hlsdiag.values()])\n",
    "print(f'There are {n_cistates} states in the HLSDIAG list')\n",
    "mat_elems = m2.soci_matelems(sosec['matel_comput'][0])\n",
    "if mat_elems:\n",
    "    print(mat_elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOCI sub-section 'basis_prop'\n",
    "if 'basis_prop' in sosec.keys():\n",
    "    basprop = m2.soci_basis_prop(sosec['basis_prop'][0], n_cistates)\n",
    "    print(basprop['DMZ'][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOCI sub-section 'so_calc'\n",
    "E0 = m2.soci_E0(sosec['so_calc'][0])\n",
    "print(f'E0 = {E0:.6f} in the SO-CI')\n",
    "somat = m2.soci_matrix(sosec['so_calc'][0])\n",
    "dimen = somat['matrix'].shape[0]\n",
    "print(f'There are {dimen} SO-CI states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero spin-orbit coupling\n",
    "offdiag =somat['matrix'].copy()\n",
    "np.fill_diagonal(offdiag, 0)\n",
    "amax = np.max(np.abs(offdiag))\n",
    "if amax == 0:\n",
    "    chem.print_err('', 'Off-diagonal elements of spin-orbit matrix are all zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to format DataFrames\n",
    "fmt = {'Eshift': '{:.1f}', 'degen': '{:.0f}'}\n",
    "for col in ['J', 'Ecalc', 'E_dif', 'Erel', 'Eshift', 'err', 'Eterm', 'cm-1',\n",
    "           'wmean', 'wstds', 'uwmean', 'uwstds', 'change', 'rwmse']:\n",
    "    fmt[col] =  fmt['Eshift']\n",
    "for col in ['dif', 'Theory', 'ecm', 'SOC', 'RMSE']:\n",
    "    fmt[col] = '{:.2f}'\n",
    "fmt['weight'] = '{:.6f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MRCI and term parentage of the basis states\n",
    "for i, bas in enumerate(somat['basis']):\n",
    "    S = bas['S']\n",
    "    lbl = bas['State']\n",
    "    subdf = dfmrci[(dfmrci.Label == lbl) & (dfmrci.S == S)]\n",
    "    #display(subdf)\n",
    "    ici = subdf.index[0]\n",
    "    bas['ici'] = ici\n",
    "    for iterm, trow in dfciterm.iterrows():\n",
    "        if ici in trow.idx:\n",
    "            bas['iterm'] = iterm\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOCI sub-section 'so_levels'\n",
    "so_energies = m2.soci_energies(sosec['so_levels'][0])\n",
    "df_soE = pd.DataFrame(so_energies)\n",
    "print(f'There are {len(df_soE)} spin-orbit levels')\n",
    "df_soE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCraw = min(so_energies['Eshift'])\n",
    "print(f'From lowest level and lowest uncoupled term energy, raw theoretical SOCraw = {SOCraw:.2f} cm-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO-CI sub-section 'so_vectors'\n",
    "# In case of symmetry blocking, the last one should be the summary\n",
    "so_vecs = m2.soci_vectors(sosec['so_vectors'][-1])\n",
    "so_vecs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check eigenvectors for normality\n",
    "#    eigenvectors are columns of so_vecs['matrix']\n",
    "tol = 1.e-7\n",
    "mat = so_vecs['matrix']\n",
    "for i in range(dimen):\n",
    "    prod = np.dot(np.conjugate(mat[:, i]), mat[:, i])\n",
    "    if np.abs(1 - prod) > tol:\n",
    "        print(i, i, ':  ', prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check eigenvectors for orthogonality\n",
    "#    eigenvectors are columns of so_vecs['matrix']\n",
    "mat = so_vecs['matrix']\n",
    "for i in range(dimen):\n",
    "    for j in range(i):\n",
    "        prod = np.dot(np.conjugate(mat[:, i]), mat[:, j])\n",
    "        if np.abs(prod) > tol:\n",
    "            print(i, j, ':  ', np.abs(prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SO-CI sub-section 'so_compos'\n",
    "so_compos = m2.soci_composition(sosec['so_compos'][0])\n",
    "so_compos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all listings of basis states are consistent\n",
    "for a, b, c in zip(somat['basis'], so_vecs['basis'], so_compos['basis']):\n",
    "    for k in a.keys():\n",
    "        if (k in b.keys()) and (k in c.keys()):\n",
    "            if (a[k] != b[k]) or (a[k] != c[k]):\n",
    "                print(a)\n",
    "                print(b)\n",
    "                print(c)\n",
    "                print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that composition is consistent with eigenvectors\n",
    "magnit = np.conjugate(so_vecs['matrix']) * so_vecs['matrix']\n",
    "# get differences in percent (printed by Molpro to 0.01% precision)\n",
    "difmat = (magnit * 100) - so_compos['matrix']\n",
    "dmax = np.abs(difmat).max()\n",
    "print(f'Largest inconsistency between composition and eigenvectors = {dmax:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert basis-state compositions (percent) to term compositions\n",
    "use_printed = False  # use composition % as printed by Molpro\n",
    "if use_printed:\n",
    "    # compositions are printed to 0.01% precision\n",
    "    print('Using compositions as printed by Molpro')\n",
    "else:\n",
    "    # eigenvectors are orthonormal and printed to 1e-8 precision\n",
    "    print('Using compositions derived from eigenvectors')\n",
    "    magpct = np.real(magnit * 100)\n",
    "term_compos = np.zeros((nterm, dimen))\n",
    "for ibas in range(dimen):\n",
    "    iterm = somat['basis'][ibas]['iterm']\n",
    "    if use_printed:\n",
    "        term_compos[iterm,:] += so_compos['matrix'][ibas,:]\n",
    "    else:\n",
    "        # use composition computed from eigenvectors\n",
    "        term_compos[iterm,:] += magpct[ibas,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add J values to dfciterm\n",
    "jpossl = []\n",
    "for term in dfciterm.term:\n",
    "    jposs = chem.possible_J_from_term(term)\n",
    "    jpossl.append(jposs)\n",
    "dfciterm['J'] = jpossl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target J counts corresponding to the CASSCF terms\n",
    "allJ = []\n",
    "for jl in dfcasterm['J_vals']:\n",
    "    allJ.extend(jl)\n",
    "J_all = dict(Counter(allJ))\n",
    "print('Required level counts     :', J_all)\n",
    "nlevels = len(allJ)\n",
    "print(f'    There are {nlevels} J-levels')\n",
    "Jxg = {k: int(v * (2*k+1)) for k, v in J_all.items()}\n",
    "J_left = Jxg.copy()  # copy to be decremented\n",
    "print('Required sublevel counts:', Jxg)\n",
    "df_soE['J'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign values of <em>J</em> to levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use term composition data to determine possible J assignment for each level\n",
    "thrpct = 10.  # percentage threshold for consideration\n",
    "print(f'Considering term compositions above {thrpct}%' +\n",
    "     ' when evaluating J possibilities')\n",
    "jpossl = []\n",
    "npossl = []\n",
    "for iso in range(dimen):\n",
    "    #print(f'Level {iso} with Erel = {df_soE.iloc[iso][\"Erel\"]}')\n",
    "    jposs = None\n",
    "    for iterm, c in enumerate(term_compos[:, iso]):\n",
    "        if c < thrpct:\n",
    "            continue\n",
    "        if jposs is None:\n",
    "            # first contributing term\n",
    "            jposs = set(dfciterm.at[iterm, 'J'])\n",
    "        else:\n",
    "            # subsequent term; take intersection\n",
    "            jposs = jposs.intersection(dfciterm.at[iterm, 'J'])\n",
    "    jpossl.append(jposs)\n",
    "    npossl.append(len(jposs))\n",
    "df_soE['J_poss'] = jpossl\n",
    "df_soE['nposs'] = npossl\n",
    "#df_soE['term_comp'] = list(np.round(term_compos, 1).T)\n",
    "df_soE['term_comp'] = list(term_compos.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for 0-possibility problems\n",
    "subdf = df_soE[df_soE.nposs < 1]\n",
    "if len(subdf):\n",
    "    print(f'*** Some levels have all possibilities eliminated ***')\n",
    "    display(subdf)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_degen = 5  # threshold (cm-1) for being clearly degenerate\n",
    "thr_big = 500  # threshold for clearly non-degenerate\n",
    "thr_tcomp = 3  # threshold (%) for similar maximum term-composition difference\n",
    "thr_tcbig = 15 # threshold (%) for clearly different term composition\n",
    "\n",
    "df_soE['J'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_unassigned = m2.assign_J_laboriously(df_soE, J_left, thr_degen, thr_big,\n",
    "                         thr_tcomp, thr_tcbig, verbose=False)\n",
    "if n_unassigned:\n",
    "    print(f'J ASSIGNMENTS FAILED FOR {n_unassigned} LEVELS')\n",
    "else:\n",
    "    print('All levels were assigned!')\n",
    "    # check the assignments against Jxg{}\n",
    "    for J, nJ in Jxg.items():\n",
    "        dfJ = df_soE[df_soE.J == J]\n",
    "        if len(dfJ) != nJ:\n",
    "            print(f'Assignment error!  For J = {J}, {nJ} levels ' +\n",
    "                  f'were needed but {len(dfJ)} were assigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dflev = m2.collect_atomic_J_sets(df_soE)\n",
    "# Add leading term\n",
    "termlist = dfciterm.term\n",
    "tlead = []\n",
    "composDl = []   # term compositions, not rounded\n",
    "TC_approx = []  # term compositions rounded for display\n",
    "shownull = True # display zero values of term compositions \n",
    "for tcomp in dflev.term_comp:\n",
    "    iterm = np.argmax(tcomp)\n",
    "    tlead.append(termlist[iterm])\n",
    "    composD = {}\n",
    "    cround1 = {}\n",
    "    for trm, pct in zip(termlist, tcomp):\n",
    "        composD[trm] = pct\n",
    "        p = round(pct, 1)\n",
    "        if (p != 0) or shownull:\n",
    "            cround1[trm] = p\n",
    "    composDl.append(composD)\n",
    "    # For display, sort by decreasing composition\n",
    "    cround1 = dict(sorted(cround1.items(), key=lambda item: item[1], reverse=True))\n",
    "    TC_approx.append(cround1)\n",
    "dflev['Lead'] = tlead\n",
    "dflev['Composition'] = composDl\n",
    "dflev['TC_approx'] = TC_approx\n",
    "Jlist = dflev.J\n",
    "Jlbl = [f'{t}_{chem.halves(J)}' for t, J in zip(tlead, Jlist)]\n",
    "dflev['Jlbl'] = Jlbl\n",
    "# reorder columns, drop 'nposs' and 'term_comp'\n",
    "dflev = dflev[['Lead', 'J', 'Jlbl', 'Erel', 'Eshift', 'Composition', 'E', 'idx',\n",
    "             'Erel_spread', 'TC_spread', 'TC_approx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Check the table below for questionable grouping of levels')\n",
    "print('\"Erel_spread\" shows how much the energies differ within a level (cm-1)')\n",
    "print('\"TC_spread\" shows how much the term compositions differ within a level (%)')\n",
    "print('\"idx\" shows which magnetic sublevels in \"df_soE\" compose each level')\n",
    "dflev[['J', 'Erel', 'Erel_spread', 'TC_spread', 'idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Level assignments from the calculation:')\n",
    "showcols = ['Lead', 'J', 'Jlbl', 'Erel', 'Eshift', 'TC_approx']\n",
    "display(dflev[showcols])\n",
    "# Are there duplicated leading terms?\n",
    "dups = False\n",
    "for j, grp in dflev.groupby('J'):\n",
    "    leads = list(grp.Lead)\n",
    "    if len(leads) > len(set(leads)):\n",
    "        print(f'*** Duplicate leading term for J = {j} ***')\n",
    "        dups = True\n",
    "        for lead in set(leads):\n",
    "            leads.remove(lead)\n",
    "        dfdup = grp[grp.Lead.isin(leads)].copy()\n",
    "        display(dfdup[showcols].style.format(fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change assignments of any duplicates\n",
    "if dups:\n",
    "    print('Correct the duplicate term assignments')\n",
    "    ifix = input('Level for which to re-assign the term? ')\n",
    "    while ifix:\n",
    "        ifix = int(ifix)\n",
    "        trm = input(f'Which term do you want to assign to level {ifix}? ')\n",
    "        dflev.loc[ifix, 'Lead'] = trm\n",
    "        ifix = input('Another level to re-assign (empty to end)? ')\n",
    "    # rebuild 'Jlbl' values\n",
    "    jlbl = [f'{t}_{chem.halves(j)}' for t, j in zip(dflev.Lead, dflev.J)]\n",
    "    dflev['Jlbl'] = chem.enumerative_prefix(jlbl)\n",
    "    display(dflev[['Lead', 'J', 'Jlbl', 'Erel', 'Eshift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for problems in assignments\n",
    "nAssign = len(set(dflev.Lead))\n",
    "nTerm = len(dfciterm)\n",
    "dropT = False\n",
    "if nAssign != nTerm:\n",
    "    print(f'*** I started with {nTerm} terms but have {nAssign} leading terms ***')\n",
    "    print('Starting: ', sorted(termsIn))\n",
    "    termsOut = set(dflev.Lead)\n",
    "    print('Leading : ', sorted(termsOut))\n",
    "    if nAssign > nTerm:\n",
    "        addT = termsOut - termsIn\n",
    "        print('Added terms: ', addT)\n",
    "    else:\n",
    "        dropT = termsIn - termsOut\n",
    "        print('Dropped terms: ', dropT)\n",
    "        # Add weights from dropped terms and display\n",
    "        for term in dropT:\n",
    "            wtcol = []\n",
    "            for comp in dflev.Composition:\n",
    "                pct = comp.get(term, 0)\n",
    "                wtcol.append(pct)\n",
    "            dflev[term] = pct\n",
    "        print('Weights (%) of dropped terms in levels:')\n",
    "        display(dfso[['Lead', 'J', 'Jlbl', 'Erel', 'Eshift'] + list(dropT)].style.format(fmt))\n",
    "nlvl = (2 * dflev.J + 1).sum()  # number of sublevels\n",
    "if nlvl != dimen:\n",
    "    print(f'*** I started with {nSO} (sub)levels but now have {nlvl} ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually assign any dropped terms\n",
    "if dropT:\n",
    "    for drt in dropT:\n",
    "        ia = int(input(f'Which level do you want to assign to term {drt}? '))\n",
    "        dflev.loc[ia, 'Lead'] = drt\n",
    "    # rebuild 'Jlbl' values\n",
    "    jlbl = [f'{t}_{chem.halves(j)}' for t, j in zip(dflev.Lead, dflev.J)]\n",
    "    dflev['Jlbl'] = chem.enumerative_prefix(jlbl)\n",
    "    display(dflev[['Lead', 'J', 'Jlbl', 'Erel', 'Eshift'] + list(dropT)].style.format(fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inversion parity of the calculated levels\n",
    "irreps_ci = set(dfciterm.irrep)\n",
    "if (PG == 'Ci') and (len(irreps_ci) == 1):\n",
    "    if 1 in irreps_ci:\n",
    "        parity = 'even'\n",
    "    else:\n",
    "        parity = 'odd'\n",
    "else:\n",
    "    # ask user for parity of interest\n",
    "    parity = input('Please choose \"even\" or \"odd\" parity: ')\n",
    "print(f'Experimental states will be restricted to parity = {parity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read experimental energy levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge = Qtot - mrci_meta['nelec']  # number of electrons in the last MRCI\n",
    "labels_ordinated = False  # flag to prevent multiple (1)(1)(1) etc. \n",
    "if charge >= 0:\n",
    "    atstr = atom + '_' + 'I' * (charge + 1)\n",
    "else:\n",
    "    # anion\n",
    "    atstr = atom + '_neg'\n",
    "fxl = f'{atstr}_exptl_levels.xlsx'\n",
    "fxlalt = None\n",
    "exp_alt = False\n",
    "# Special cases\n",
    "if atstr == 'Ra_I':\n",
    "    fxlalt = 'Ra_I_exptl_levels_plus_theory.xlsx'\n",
    "#if atstr in ['Ar_I', 'Pb_I', 'Kr_I']:\n",
    "if atstr in ['Ar_I', 'Pb_I']:\n",
    "    fxlalt = f'{atstr}_exptl_even_assign.xlsx'\n",
    "if atstr in ['Br_I', 'I_I']:\n",
    "    fxlalt = f'{atstr}_exptl_odd_assign.xlsx'\n",
    "\n",
    "if fxlalt is not None:\n",
    "    print('** Using alternative experimental data file ***')\n",
    "    exp_alt = True\n",
    "    fxl = fxlalt\n",
    "xlpath = os.sep.join([fdir, fxl])\n",
    "dfexpt = pd.read_excel(xlpath)\n",
    "if exp_alt and ('LS' in dfexpt.columns):\n",
    "    # use manual assignments\n",
    "    print('** Using term labels in column \"LS\"')\n",
    "    dfexpt.loc[dfexpt['LS'].notnull(), 'Term'] = dfexpt[dfexpt['LS'].notnull()]['LS']\n",
    "    #dfexpt['Term'] = dfexpt['LS']\n",
    "print(f'Experimental energy levels read from {fxl}')\n",
    "# If there is a column \"comment\", replace NaN with ''\n",
    "if 'comment' in dfexpt.columns:\n",
    "    dfexpt['comment'] = dfexpt['comment'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of decimal places in the level energies\n",
    "Ecol = 'Level (cm-1)'  # the exptl energy column\n",
    "ndecim = 0\n",
    "for e in dfexpt[Ecol]:\n",
    "    words = str(e).split('.')\n",
    "    # count numeric digits\n",
    "    n = sum(c.isdigit() for c in words[-1])\n",
    "    ndecim = max(n, ndecim)\n",
    "print(f'Experimental energies are provided to {ndecim} decimal digits')\n",
    "# display formatting\n",
    "fmt[Ecol] = '{:.' + str(ndecim) + 'f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Delete any ionization limit\n",
    "ilim = dfexpt[dfexpt.Term == 'Limit'].index.min()\n",
    "# delete the \"Limit\" row and everything past it\n",
    "n1 = len(dfexpt)\n",
    "dfexpt = dfexpt.truncate(after=ilim-1)\n",
    "n2 = len(dfexpt)\n",
    "if n2 < n1:\n",
    "    print(f'Discarding {n1-n2} ionized or metastable states')\n",
    "oddstr = r'\\*$|°' # characters to identify terms of odd parity\n",
    "# Sometimes parity is shown in configuration alone?\n",
    "#dfeven = dfexpt[~(dfexpt.Term.str.contains(oddstr) | dfexpt.Configuration.str.contains(oddstr))].copy()\n",
    "#dfodd = dfexpt[dfexpt.Term.str.contains(oddstr) | dfexpt.Configuration.str.contains(oddstr)].copy()\n",
    "dfeven = dfexpt[~(dfexpt.Term.str.contains(oddstr))].copy()\n",
    "dfodd = dfexpt[dfexpt.Term.str.contains(oddstr)].copy()\n",
    "print(f'{len(dfexpt)} experimental levels ({len(dfeven)} even and {len(dfodd)} odd)')\n",
    "# Select by parity\n",
    "if parity == 'even':\n",
    "    # discard odd levels ('Term' field ends with '*')\n",
    "    dfexpt = dfeven.copy()\n",
    "elif parity == 'odd':\n",
    "    dfexpt = dfodd.copy()\n",
    "else:\n",
    "    chem.print_err('', f'Parity of \"{parity}\" is not recognized')\n",
    "n3 = len(dfexpt)\n",
    "print(f'{n3} levels accepted for parity = {parity}')\n",
    "# Reject bad values of J\n",
    "for i in dfexpt.index:\n",
    "    try:\n",
    "        chem.halves_to_float(dfexpt.loc[i, 'J'])\n",
    "    except ValueError:\n",
    "        dfexpt.at[i, 'J'] = np.nan\n",
    "nbad = dfexpt.J.isna().sum()\n",
    "if nbad:\n",
    "    print(f'** Rejecting {nbad} levels with malformed J values')\n",
    "    dfexpt = dfexpt.dropna()\n",
    "    n4 = len(dfexpt)\n",
    "    print(f'{n4} level retained')\n",
    "# Assign unique term symbols\n",
    "if not labels_ordinated:\n",
    "    dfexpt = chem.unique_labels_exptl_terms(dfexpt, verbose=True, always=True)\n",
    "    labels_ordinated = True\n",
    "# Add column for degeneracy\n",
    "dfexpt['degen'] = (2 * dfexpt.J.apply(chem.halves_to_float)).astype(int) + 1\n",
    "dfexpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_term_symbol(symb_expt, symb_calc):\n",
    "    # Return True if they are the same, else False\n",
    "    # Tolerate extra prefix '(1)' or 'a ' in symb_expt\n",
    "    retval = (symb_calc == symb_expt)  # exact match\n",
    "    tx = symb_expt[-len(symb_calc):]   # match last characters\n",
    "    retval |= (symb_calc == tx)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def match_theory_to_expt(dfth, dfx, bigerr=2000):\n",
    "    '''\n",
    "    Match experimental levels to theoretical\n",
    "    Return a DataFrame containing both theory and expt, and\n",
    "      the index of the highest level matched\n",
    "    'bigerr' is in cm-1 and triggers extra scrutiny\n",
    "    '''\n",
    "    print('Matching experimental levels with theoretical levels')\n",
    "    Jlist = sorted(set(dfth.J))\n",
    "    dfcomp = dfexpt.copy()\n",
    "    dfcomp['Tcalc'] = ''  # term assignment in computation\n",
    "    dfcomp['leadwt'] = ''\n",
    "    dfcomp['Ecalc'] = np.nan\n",
    "    dfcomp['termwt'] = None\n",
    "    dfcomp['Composition'] = None\n",
    "    imax = 0  # index of highest exptl level matched\n",
    "    integerJ = (Jlist[0] == int(Jlist[0]))\n",
    "    for J in Jlist:\n",
    "        print(f'J = {J}')\n",
    "        # get the indices of the exptl levels that best match theoretical\n",
    "        dfJth = dflev[dflev.J == J]\n",
    "        #display(dfJth[['Lead', 'J', 'Erel', 'TC_approx']])\n",
    "        dfJx = dfexpt[dfexpt.J == J]\n",
    "        if len(dfJx) < 1:\n",
    "            # try str representation\n",
    "            hJstr = chem.halves(J)  # as str fraction\n",
    "            dfJx = dfexpt[dfexpt.J == hJstr]\n",
    "        #display(dfJx)\n",
    "        idx = match_th_expt_1J_V2(dfJth, dfJx, bigerr=bigerr)\n",
    "        for i, ix in enumerate(idx):\n",
    "            rowth = dfJth.iloc[i]\n",
    "            dfcomp.at[ix, 'Tcalc'] = rowth.Lead\n",
    "            dfcomp.at[ix, 'leadwt'] = rowth.TC_approx[rowth.Lead]\n",
    "            dfcomp.at[ix, 'Ecalc'] = rowth.Erel\n",
    "            dfcomp.at[ix, 'termwt'] = chem.sort_dict_by_value(rowth.TC_approx,\n",
    "                                        reverse=True)\n",
    "            dfcomp.at[ix, 'Composition'] = rowth.Composition\n",
    "            imax = max(imax, ix)\n",
    "    return dfcomp, imax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_th_expt_1J_V2(dfJth, dfJx, bigerr=2000):\n",
    "    '''\n",
    "    Given DataFrame's of theoretical and experimental levels for the same J,\n",
    "    Return a list of indices into dfJx that match those in dfJth\n",
    "        based upon energy, but with preference for same leading term\n",
    "    'bigerr' is in cm-1 and triggers extra scrutiny\n",
    "    '''\n",
    "    idx = []  # index of exptl level that matches each theor level\n",
    "    for i, row in dfJth.iterrows():\n",
    "        Eth = row.Erel\n",
    "        thTerm = row.Lead\n",
    "\n",
    "        def same_Lead(xTerm):\n",
    "            # Does the exptl \"Term\" match the theoretical \"Lead\"?\n",
    "            return match_term_symbol(xTerm, thTerm)\n",
    "    \n",
    "        # Is there an exptl level with the same leading term?\n",
    "        termatch = dfJx.Term.apply(same_Lead)\n",
    "        subx = dfJx.loc[termatch]\n",
    "        if len(subx) == 1:\n",
    "            # The nicest situation\n",
    "            print(f'    exptl term \"{subx.Term.iloc[0]}\" matches leading \"{thTerm}\"')\n",
    "            j = subx.index.values[0]\n",
    "        else:\n",
    "            # There are multiple or no matching terms\n",
    "            #   rely upon energy ordering (among matching terms, if any)\n",
    "            if len(subx) > 1:\n",
    "                # Exptl data assign the same leading term to multiple levels of this J (unusual)\n",
    "                #print(f'    leading \"{thTerm}\" matches multiple exptl terms \"{subx.Term.values}\"')\n",
    "                pass\n",
    "            else:\n",
    "                # No matching term symbols\n",
    "                #print(f'    leading \"{thTerm}\" matches no exptl term labels')\n",
    "                subx = dfJx  # consider all levels because none match the term symbol\n",
    "            for j, rowx in subx.iterrows():\n",
    "                # expect energy ordering to be similar\n",
    "                #    there is no way to detect inversions\n",
    "                if j in idx:\n",
    "                    # this exptl level already matched\n",
    "                    continue\n",
    "                # we get here if this level has not yet been matched; take the first one\n",
    "                print(f'    leading \"{thTerm}\" matched with exptl \"{rowx.Term}\"')\n",
    "                break\n",
    "        idx.append(j)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Match theoretical and experimental levels\n",
    "# imax is the index of the highest-energy level matched\n",
    "dfdiff, imax = match_theory_to_expt(dflev, dfexpt)\n",
    "dfdiff['err'] = dfdiff.Ecalc - dfdiff[Ecol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = dfdiff.loc[imax, 'Tcalc']\n",
    "J = dfdiff.loc[imax, 'J']\n",
    "levmax = f'{t}_{J}'\n",
    "emax = dfdiff.loc[imax, Ecol]\n",
    "showcols = ['Configuration', 'uTerm', 'Tcalc', 'J', Ecol, 'Ecalc', 'err', 'termwt']\n",
    "print(f'\\nHighest level matched is {levmax} at {emax} cm-1 (exptl energy)')\n",
    "# Notify about any exptl levels that the calculation skipped over\n",
    "dfskipped = dfdiff[dfdiff.Ecalc.isna()].loc[:imax]\n",
    "if len(dfskipped):\n",
    "    print('** Some experimental levels are skipped in the calculation **')\n",
    "    display(dfskipped)\n",
    "    #display(dfdiff.loc[:imax][showcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert str values of J to float\n",
    "dfdiff['J'] = dfdiff.J.apply(chem.halves_to_float)\n",
    "warnThresh = 1000  # highlight errors larger than this (cm-1)\n",
    "# drop rows with NaN (no matching level in the calculation)\n",
    "dfdiff = dfdiff.dropna(axis=0)\n",
    "#selcols = ['Configuration', 'uTerm', 'J', Ecol, 'Tcalc', 'Ecalc', 'err']\n",
    "# Print a warning if experimental levels are missing\n",
    "nth = len(dflev); ndiff = len(dfdiff)\n",
    "expt_missing = nth - ndiff\n",
    "if expt_missing > 0:\n",
    "    print(f'\\n**** There are {nth} theoretical levels but only {ndiff} matching experimental levels ****')\n",
    "else:\n",
    "    # use as flag\n",
    "    expt_missing = 0\n",
    "if 'comment' in dfdiff.columns:\n",
    "    selcols.append('comment')\n",
    "print(f'Please inspect the following pairing of theory (\"Ecalc\") with expt (\"{Ecol}\")')\n",
    "print('Disagreements in term assignments are highlighted in red')\n",
    "print(f'Errors > {warnThresh} cm-1 are highlighted in yellow')\n",
    "display(dfdiff[showcols].style.apply(lambda x: [\"background: yellow\" if abs(v) > warnThresh else \"\" for v in x], \n",
    "              subset=pd.IndexSlice[['err']]).apply(lambda x: (~match_term_symbol(dfdiff['uTerm'], x)).map({True: \"background-color: red; \\\n",
    "              color: white\", False: \"\"}), subset=['Tcalc']).format(fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No theoretical calculations are needed to use eq. (1)\n",
    "xterms = []  # list of term labels\n",
    "eterms = []  # list of term energies\n",
    "for term in dfdiff.uTerm:\n",
    "    if term not in xterms:\n",
    "        xterms.append(term)\n",
    "for Term in xterms:\n",
    "    subdf = dfexpt[dfexpt.uTerm == Term]\n",
    "    emean = np.dot(subdf.degen, subdf[Ecol]) / subdf.degen.sum()\n",
    "    eterms.append(emean)\n",
    "dfeq1 = pd.DataFrame({'Term': xterms, 'Eterm': eterms}).sort_values('Eterm').reset_index(drop=True)\n",
    "print('Term energies (cm-1) using eq. (1) (experimental data with naive model)')\n",
    "display(dfeq1.style.format(fmt))\n",
    "SOC1 = -1 * np.round(dfeq1.at[0, 'Eterm'], 3)\n",
    "lowterm = dfeq1.at[0, 'Term']\n",
    "print(f'The term of lowest energy is \\t{lowterm} \\twith SOC1 = {SOC1} cm-1')\n",
    "levterm = dfexpt.uTerm.values[0]\n",
    "\n",
    "target = levterm\n",
    "\n",
    "if levterm != lowterm:\n",
    "    # The lowest term is not the leading term in the lowest level\n",
    "    SOC1alt = SOC1\n",
    "    SOC1 = -1 * np.round(dfeq1[dfeq1.Term == levterm]['Eterm'].values[0], 3)\n",
    "    print(f'The lowest level belongs to \\t{levterm} \\twith SOC1 = {SOC1} cm-1')\n",
    "print()\n",
    "print(f'Term {target} is selected for calculating the spin-orbit correction')\n",
    "print('    to change this, assign the variable \"target\" to another term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_energy_from_levels(df, term, returnDF=False):\n",
    "    # Given a DataFrame with the right columns ['J', 'Composition', Ecol],\n",
    "    #   where 'Ecol' is the header for the column of exptl level energies,\n",
    "    # Return the term's average energy as derived from the levels [eq. (2) in pub.]\n",
    "    # If 'returnDF', also return a DataFrame for the selected term\n",
    "    termwt = []  # weight of term \"term\" in each level\n",
    "    compos = df.Composition.values\n",
    "    for twt in compos:\n",
    "        if term not in twt.keys():\n",
    "            # maybe need to remove leading \"(1)\"\n",
    "            term = term.replace('(1)', '')\n",
    "        try:\n",
    "            termwt.append(twt[term])\n",
    "        except KeyError:\n",
    "            # can't find this term among theoretical terms\n",
    "            return None, None\n",
    "    termwt = np.array(termwt)\n",
    "    dweight = df.degen.values * termwt  # weights including degeneracies\n",
    "    Eterm = np.dot(df[Ecol], dweight) / dweight.sum()\n",
    "    if not returnDF:\n",
    "        return Eterm\n",
    "    # Construct DF showing distribution of term among levels\n",
    "    cols = ['Configuration', 'uTerm', 'Tcalc', 'J', 'degen', Ecol, 'Ecalc', 'err']\n",
    "    df_distrib = df[cols].copy()\n",
    "    df_distrib.insert(0, 'weight', termwt / 100)  # fraction instead of percent\n",
    "    return Eterm, df_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use experimental level energies via eq. (2) (from the publication)\n",
    "Eterm, df_distrib = term_energy_from_levels(dfdiff, target, returnDF=True)\n",
    "SOC2 = -Eterm\n",
    "print('Applying eq. (2) (experimental energies and theoretical term weights)')\n",
    "print(f'For term {target}, SOC2 = {SOC2:.2f} cm-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Distribution of term {target} among levels:')\n",
    "wthr = 1.e-6  # minimum weight to display\n",
    "dfshow = df_distrib[df_distrib.weight > wthr]\n",
    "display(dfshow.sort_values('weight', ascending=False).style.format(fmt))\n",
    "wtot = dfshow.weight.sum()\n",
    "dwtot = np.dot(dfshow.weight, dfshow.degen)\n",
    "print('Total displayed weight = {:.3f} ({:.3f} including degeneracies)'.format(wtot, dwtot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Molpro source file: {fname}\\n')\n",
    "print(f'Alternative values for E_so[{target}] of atom {atom}:')\n",
    "print('-' * 25)\n",
    "print('{:12s} {:.2f} cm-1'.format('eq (1)', SOC1))\n",
    "print('{:12s} {:.2f} cm-1'.format('raw theory', SOCraw))\n",
    "print('{:12s} {:.2f} cm-1'.format('eq (2)', SOC2))\n",
    "print('-' * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term energy errors as inferred from all levels\n",
    "termlist = []\n",
    "wmean = []\n",
    "wstds = []\n",
    "# also consider unsigned (absolute value) errors\n",
    "uwmean = []\n",
    "uwstds = []\n",
    "# also consider RMSE\n",
    "trmse = []\n",
    "for term in set(dfdiff.uTerm):\n",
    "    eterm, df_distro = term_energy_from_levels(dfdiff, term, returnDF=True)\n",
    "    if eterm is None:\n",
    "        print(f'No theoretical term matches exptl {term}')\n",
    "        continue\n",
    "    termlist.append(term)\n",
    "    wts = df_distro.weight.values * df_distro.degen\n",
    "    m, s = chem.weighted_mean(df_distro.err, wts)\n",
    "    wmean.append(m)\n",
    "    wstds.append(s)\n",
    "    uerr = np.abs(df_distro.err.values)\n",
    "    um, us = chem.weighted_mean(uerr, wts)\n",
    "    uwmean.append(um)\n",
    "    uwstds.append(us)\n",
    "    umsq, ussq = chem.weighted_mean(uerr ** 2, wts)\n",
    "    trmse.append(np.sqrt(umsq))\n",
    "dftermerr = pd.DataFrame({'Term': termlist, 'wmean': wmean, 'wstds': wstds,\n",
    "                         'uwmean': uwmean, 'uwstds': uwstds, 'rwmse': trmse})\n",
    "\n",
    "print('Errors in term energies (cm-1) as inferred from the full distribution')\n",
    "print('    of each term over all levels')\n",
    "# default order same as experimental terms\n",
    "dftermerr.Term = pd.Categorical(dftermerr.Term, xterms)\n",
    "dftermerr = dftermerr.sort_values('Term')\n",
    "#dftermerr.sort_values('uwmean').style.format(fmt)\n",
    "dftermerr.style.format(fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional distribution of some other term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_term = '(1)2P'\n",
    "Eterm, df_distrib = term_energy_from_levels(dfdiff, other_term, returnDF=True)\n",
    "if Eterm is None:\n",
    "    print(f'*** Cannot evaluate errors for levels within term \"{other_term}\"')\n",
    "else:\n",
    "    print(f'Distribution of term {other_term} among levels:')\n",
    "    display(df_distrib.sort_values('weight', ascending=False).style.format(fmt))\n",
    "    wtot = df_distrib.weight.sum()\n",
    "    dwtot = np.dot(df_distrib.weight, df_distrib.degen)\n",
    "    print('Total weight = {:.3f} ({:.3f} including degeneracies)'.format(wtot, dwtot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
